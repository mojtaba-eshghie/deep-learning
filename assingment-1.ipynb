{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -y line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[b'batch_label', b'labels', b'data', b'filenames']\nb'training batch 1 of 5'\n10000\n[ 59  43  50 ... 140  84  72]\n6\n(3072,)\n"
     ]
    }
   ],
   "source": [
    "dict = unpickle('dataset/data_batch_1')\n",
    "print(list(dict.keys()))\n",
    "print(dict[b'batch_label'])\n",
    "print(dict[b'filenames'].__len__())\n",
    "\n",
    "print(dict[b'data'][0])\n",
    "print(dict[b'labels'][0])\n",
    "print(dict[b'data'][0].shape)\n",
    "#print(dict[b'data'][0].resahpe(32, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Image.fromarray(dict[b'data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sample.jpg'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-964873ec927e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2878\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2879\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "im = Image.open('sample.jpg')\n",
    "a = np.asarray(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cifar10_plot(data, img_index=1):\n",
    "    im = data[b'data'][img_index, :]\n",
    "\n",
    "    im_r = im[0:1024].reshape(32, 32)\n",
    "    im_g = im[1024:2048].reshape(32, 32)\n",
    "    im_b = im[2048:].reshape(32, 32)\n",
    "\n",
    "    # this is the funciton I was looking for the whole time...\n",
    "    img = np.dstack((im_r, im_g, im_b))\n",
    "\n",
    "    print(\"shape: \", img.shape)\n",
    "    print(\"label: \", data[b'labels'][img_index])\n",
    "    \n",
    "    #print(\"category:\", meta[b'label_names'][data[b'labels'][im_idx]])         \n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "cifar10_plot(dict)"
   ]
  },
  {
   "source": [
    "# Assignment #1 \n",
    "\n",
    "train set: data_batch_1\n",
    "\n",
    "validation set: data_batch_2\n",
    "\n",
    "test set: test_batch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unpickle(file, n=10000):\n",
    "    \"\"\"\n",
    "    Parameters: \n",
    "    file (str): file address \n",
    "    num (int): number of datapoints in the file\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    import copy \n",
    "\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    \n",
    "    # let's make the Y (which is a K*n matrix of the one-hot representations of the label of each image)\n",
    "    Y = np.zeros((10, n))\n",
    "    zero_list = [0 for i in range(10)]\n",
    "    i = 0\n",
    "    for a in dict[b'labels']:\n",
    "        '''\n",
    "        right = str(bin(a+1)).split('b')[1]\n",
    "        one_hot = np.array(list('0'*(10-len(right))+right))\n",
    "        '''\n",
    "        one_hot = copy.deepcopy(zero_list)\n",
    "        one_hot[int(a)] = 1\n",
    "        Y[:, i] = one_hot\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "\n",
    "    return dict[b'data'].T, Y, np.array(dict[b'labels'])\n",
    "\n",
    "train_X, train_Y, train_y = unpickle('dataset/data_batch_1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data_):\n",
    "    \"\"\"\n",
    "    This is used to normalize the data w.r.t mean and std: (x - mean) / std\n",
    "    \"\"\"\n",
    "    data = np.copy(data_)\n",
    "    shape = data.shape\n",
    "    mean = np.mean(data, 1)\n",
    "    std = np.std(data, 1)\n",
    "\n",
    "\n",
    "    for i in range(data.shape[1]):\n",
    "        data[:, i] = (data[:, i] - mean) / std\n",
    "\n",
    "    return data\n",
    "    \n",
    "n_train_X = normalize(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3072, 10000)"
      ]
     },
     "metadata": {},
     "execution_count": 585
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3072, 10000)"
      ]
     },
     "metadata": {},
     "execution_count": 586
    }
   ],
   "source": [
    "n_train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "print(train_X[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(n_train_X[100, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(n_train_X[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "print(train_X[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "131.3316\n72.79520891816986\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(train_X, 1)[1])\n",
    "print(np.std(train_X, 1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(n_train_X[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 59, 154, 255, ...,  71, 250,  62],\n",
       "       [ 43, 126, 253, ...,  60, 254,  61],\n",
       "       [ 50, 105, 253, ...,  74, 211,  60],\n",
       "       ...,\n",
       "       [140, 139,  83, ...,  68, 215, 130],\n",
       "       [ 84, 142,  83, ...,  69, 255, 130],\n",
       "       [ 72, 144,  84, ...,  68, 254, 131]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 593
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatchGDNN:\n",
    "    \n",
    "    def __init__(self, k, d):\n",
    "        # k is the number of classes\n",
    "        # d is the data dimention\n",
    "        self.k = k\n",
    "        self.d = d\n",
    "\n",
    "        # initializing the weight matrix\n",
    "        self.W = np.random.normal(0, 0.01, (k, d))\n",
    "        self.b = np.random.normal(0, 0.01, (k, 1))\n",
    "\n",
    "    \n",
    "    def evaluate_classifier(self, X, W, b):\n",
    "        # Each column in X corresponds to 'one' image in this context having the d*n size\n",
    "        # This function returns: k*n, each row contains probability for the specific class\n",
    "\n",
    "        if len(X.shape) >= 2:\n",
    "            second_dimention = X.shape[1]\n",
    "            temp_b = np.array(b * second_dimention)\n",
    "            result = np.dot(W, X) + temp_b\n",
    "        else:\n",
    "            second_dimention = 0\n",
    "            temp_b = b\n",
    "            result = np.dot(W, X).reshape(10, 1) + temp_b\n",
    "        \n",
    "        \n",
    "\n",
    "        P = np.zeros(result.shape).shape\n",
    "        \n",
    "        if second_dimention:\n",
    "            P = np.zeros(result.shape)\n",
    "            for j in range(second_dimention):\n",
    "                P[:, j] = np.exp(result[:, j]) / sum(np.exp(result[:, j]))\n",
    "        else:\n",
    "            P = np.zeros((result.shape[0], 1))\n",
    "            P = (np.exp(result) / sum(np.exp(result))).reshape((self.k, 1))\n",
    "            # just one row of elements in P\n",
    "        \n",
    "        return P\n",
    "    \n",
    "\n",
    "    def compute_cost(self, X, Y, W, b, lambda_):\n",
    "        n = X.shape[1]\n",
    "        r = np.sum(np.square(self.W))\n",
    "        P = self.evaluate_classifier(X, W, b)\n",
    "        l = 0\n",
    "        for i in range(n):\n",
    "            y = Y[:, i]\n",
    "            p = P[:, i]\n",
    "            probability = np.dot(y, p)\n",
    "\n",
    "            if not probability:\n",
    "                '''\n",
    "                print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "                print('y is {0}\\n p is: {1}'.format(y, p))\n",
    "                print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "                '''\n",
    "                probability = 1.00e-100\n",
    "\n",
    "\n",
    "            assert probability\n",
    "\n",
    "            l = - np.log(probability)\n",
    "            \n",
    "            if not l:\n",
    "                print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "                print('probablity: {}'.format(probability))\n",
    "                print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "            \n",
    "            assert l\n",
    "            \n",
    "        J = (l / n) + (lambda_ * r)\n",
    "        \n",
    "        return J\n",
    "    \n",
    "    def accuracy(self, X, y, W, b):\n",
    "        # y is a vector containing the ground truth label numbers (just like train_y)\n",
    "        P = self.evaluate_classifier(X, W, b)\n",
    "        prediction = np.argmax(P, axis=0)\n",
    "        n = X.shape[1]\n",
    "        incorrect = 0\n",
    "        for i in range(n):\n",
    "            if y[i] != prediction[i]:\n",
    "                incorrect += 1\n",
    "        return (n - incorrect) / n\n",
    "    \n",
    "\n",
    "    def compute_grads_num_slow(self, X, Y, P, W, b, lamda_, h=0.01):\n",
    "        \n",
    "\n",
    "        no \t= \tW.shape[0]\n",
    "        d \t= \tX.shape[0]\n",
    "\n",
    "        grad_W = np.zeros(W.shape)\n",
    "        grad_b = np.zeros((no, 1))\n",
    "\n",
    "\n",
    "        \n",
    "        for i in range(len(b)):\n",
    "            b_try = np.array(b)\n",
    "            b_try[i] -= h\n",
    "            c1 = self.compute_cost(X, Y, W, b_try, lamda_)\n",
    "\n",
    "            b_try = np.array(b)\n",
    "            b_try[i] += h\n",
    "            c2 = self.compute_cost(X, Y, W, b_try, lamda_)\n",
    "\n",
    "            grad_b[i] = (c2-c1) / (2*h)\n",
    "        \n",
    "\n",
    "        for i in range(W.shape[0]):\n",
    "            print('>> inside grad computation main loop, i: {}'.format(i))\n",
    "            for j in range(W.shape[1]):\n",
    "\n",
    "                W_try = np.array(W)\n",
    "                W_try[i,j] -= h\n",
    "                c1 = self.compute_cost(X, Y, W_try, b, lamda_)\n",
    "\n",
    "                W_try = np.array(W)\n",
    "                W_try[i,j] += h\n",
    "                c2 = self.compute_cost(X, Y, W_try, b, lamda_)\n",
    "\n",
    "                grad_W[i,j] = (c2-c1) / (2*h)\n",
    "\n",
    "                \n",
    "                if np.isnan(grad_W[i,j]):\n",
    "                    print('You are in a bad situation...')\n",
    "                    print(2*h)\n",
    "                    print(c1)\n",
    "                    print(c2)\n",
    "                    print('X: \\n {}'.format(X))\n",
    "                    print('Y: \\n {}'.format(Y))\n",
    "                    print('Is W_try nan: {0}\\nW_try: \\n {1}'.format(np.isnan(np.sum(W_try)), W_try))\n",
    "                    print('Is b nan: {0}\\nb: \\n {1}'.format(np.isnan(np.sum(b)), b))\n",
    "                    print('lambda: {}'.format(lamda_))\n",
    "                    print('#####################')\n",
    "                \n",
    "                \n",
    "\n",
    "        if np.isnan(np.sum(grad_W)):\n",
    "            print('\\n.   ^^^^^^^^^^^^^^^^^^^^ smt bad: ')\n",
    "        \n",
    "        assert not np.isnan(np.sum(grad_W))\n",
    "\n",
    "        return [grad_W, grad_b]\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, X, Y, eta=0.01, lambda_=0, epochs=100, mini_batch_size=100):\n",
    "        # forward pass\n",
    "        # backward pass\n",
    "        # update weight matrix\n",
    "        \n",
    "        # let's do a permutation of the total dataset size!\n",
    "        n = X.shape[1]\n",
    "        assert n % mini_batch_size == 0\n",
    "        for i in range(epochs):\n",
    "            '''\n",
    "            # if we use train_y as well:\n",
    "            temp1 = np.concatenate((train_X, train_Y))\n",
    "            temp2 = train_y.reshape((train_y.shape[0], 1)).T\n",
    "            stacked_arrays = np.concatenate((temp1, temp2)).shape\n",
    "            '''\n",
    "            stacked_arrays = np.concatenate((X, Y))\n",
    "            np.take(stacked_arrays, np.random.permutation(n), axis=1, out=stacked_arrays)\n",
    "            X_, Y_ = np.split(stacked_arrays, [self.d], axis=0)\n",
    "\n",
    "            num_of_batches = int(n / mini_batch_size)\n",
    "            l_index = 0\n",
    "            h_index = 0\n",
    "            for i in range(num_of_batches):\n",
    "                l_index = h_index\n",
    "                h_index = (i+1) * mini_batch_size\n",
    "                batch_X = X_[:, l_index:h_index]\n",
    "                batch_Y = Y_[:, l_index:h_index]\n",
    "                P = self.evaluate_classifier(batch_X, self.W, self.b)\n",
    "\n",
    "                grad_W, grad_b = self.compute_grads_num_slow(batch_X, batch_Y, P, self.W, self.b, lambda_)\n",
    "                \n",
    "                print('******** grads computed, batch number: {}'.format(i))\n",
    "                \n",
    "                # TODO: remove this:\n",
    "                print('shape of W: {}'.format(self.W.shape))\n",
    "                print('shape of grad_W: {}'.format(grad_W.shape))\n",
    "                print('shape of b: {}'.format(self.b.shape))\n",
    "                print('shape of grad_b: {}'.format(grad_b.shape))\n",
    "                print('this is grad_W:')\n",
    "                print(grad_W)\n",
    "                print('dtype of grad_W: {0}, dtype of W: {1}'.format(self.W.dtype, grad_W.dtype))\n",
    "                print('eta is: {}'.format(eta))\n",
    "                print('result of operation (temp): ')\n",
    "                print(self.W - (eta * grad_W))\n",
    "                '''import time\n",
    "                time.sleep(10)'''\n",
    "\n",
    "\n",
    "                self.W = self.W - (eta * grad_W)\n",
    "                self.b = self.b - (eta * grad_b)\n",
    "\n",
    "                # TODO: remove this\n",
    "                print('------------------------')\n",
    "            \n",
    "            # TODO: remove this\n",
    "            print('epoch ended...')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MiniBatchGDNN(k=10, d=5)\n",
    "#res = nn.evaluate_classifier(train_X[:, 0], nn.W, nn.b)\n",
    "#nn.compute_cost(n_train_X, train_Y, nn.W, nn.b, 0.01)\n",
    "#nn.accuracy(n_train_X, train_y, nn.W, nn.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 0\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01449816  0.00221223 -0.00938178  0.00607518  0.01157121]\n",
      " [ 0.00837532 -0.00377475  0.01097295 -0.01057078  0.00586676]\n",
      " [ 0.0235476   0.00161914 -0.00659314  0.00225974 -0.0112262 ]\n",
      " [-0.0010422  -0.02423056  0.00116828  0.00190574 -0.00707759]\n",
      " [-0.00949748  0.01541678 -0.00065701  0.00744265  0.01613896]\n",
      " [ 0.01890099  0.00049018 -0.00095693  0.00736534  0.00224035]\n",
      " [ 0.00457766  0.00677047  0.01447364  0.00314058  0.00035536]\n",
      " [ 0.00957279  0.0080289  -0.0120513  -0.02213041  0.00172154]\n",
      " [ 0.0104276   0.00403532  0.01176052 -0.00016392  0.01213773]\n",
      " [ 0.00369765 -0.00257399  0.01600026 -0.00304281  0.00602765]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 1\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[-2.54976092e+00 -2.54976092e+00 -2.54976092e+00 -2.54976092e+00\n",
      "  -2.54976092e+00]\n",
      " [ 5.90836760e-03  5.90836760e-03  5.90836760e-03  5.90836760e-03\n",
      "   5.90836760e-03]\n",
      " [ 1.04936625e-02  1.04936625e-02  1.04936625e-02  1.04936625e-02\n",
      "   1.04936625e-02]\n",
      " [ 1.65337639e-07  1.65337639e-07  1.65337639e-07  1.65337639e-07\n",
      "   1.65337639e-07]\n",
      " [ 3.31994887e-01  3.31994887e-01  3.31994887e-01  3.31994887e-01\n",
      "   3.31994887e-01]\n",
      " [ 1.09437295e-01  1.09437295e-01  1.09437295e-01  1.09437295e-01\n",
      "   1.09437295e-01]\n",
      " [ 1.54922394e-01  1.54922394e-01  1.54922394e-01  1.54922394e-01\n",
      "   1.54922394e-01]\n",
      " [ 1.09322419e-05  1.09322419e-05  1.09322419e-05  1.09322419e-05\n",
      "   1.09322419e-05]\n",
      " [ 2.05195912e+00  2.05195912e+00  2.05195912e+00  2.05195912e+00\n",
      "   2.05195912e+00]\n",
      " [ 4.74410714e-03  4.74410714e-03  4.74410714e-03  4.74410714e-03\n",
      "   4.74410714e-03]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[ 0.01099945  0.02770984  0.01611583  0.03157279  0.03706882]\n",
      " [ 0.00831623 -0.00383383  0.01091386 -0.01062986  0.00580767]\n",
      " [ 0.02344267  0.0015142  -0.00669807  0.00215481 -0.01133114]\n",
      " [-0.00104221 -0.02423056  0.00116828  0.00190574 -0.00707759]\n",
      " [-0.01281743  0.01209683 -0.00397696  0.0041227   0.01281901]\n",
      " [ 0.01780662 -0.00060419 -0.00205131  0.00627096  0.00114598]\n",
      " [ 0.00302843  0.00522125  0.01292441  0.00159136 -0.00119387]\n",
      " [ 0.00957268  0.00802879 -0.01205141 -0.02213052  0.00172143]\n",
      " [-0.010092   -0.01648427 -0.00875907 -0.02068351 -0.00838186]\n",
      " [ 0.00365021 -0.00262143  0.01595281 -0.00309025  0.00598021]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 2\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 2.55000000e+00  2.55000000e+00  2.55000000e+00  2.55000000e+00\n",
      "   2.55000000e+00]\n",
      " [ 4.10782519e-13  4.10782519e-13  4.10782519e-13  4.10782519e-13\n",
      "   4.10782519e-13]\n",
      " [ 6.88338275e-13  6.88338275e-13  6.88338275e-13  6.88338275e-13\n",
      "   6.88338275e-13]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 4.38538095e-13  4.38538095e-13  4.38538095e-13  4.38538095e-13\n",
      "   4.38538095e-13]\n",
      " [ 2.17048601e-12  2.17048601e-12  2.17048601e-12  2.17048601e-12\n",
      "   2.17048601e-12]\n",
      " [ 1.77080572e-12  1.77080572e-12  1.77080572e-12  1.77080572e-12\n",
      "   1.77080572e-12]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-2.55000000e+00 -2.55000000e+00 -2.55000000e+00 -2.55000000e+00\n",
      "  -2.55000000e+00]\n",
      " [ 3.38618023e-13  3.38618023e-13  3.38618023e-13  3.38618023e-13\n",
      "   3.38618023e-13]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01450055  0.00220984 -0.00938417  0.00607279  0.01156882]\n",
      " [ 0.00831623 -0.00383383  0.01091386 -0.01062986  0.00580767]\n",
      " [ 0.02344267  0.0015142  -0.00669807  0.00215481 -0.01133114]\n",
      " [-0.00104221 -0.02423056  0.00116828  0.00190574 -0.00707759]\n",
      " [-0.01281743  0.01209683 -0.00397696  0.0041227   0.01281901]\n",
      " [ 0.01780662 -0.00060419 -0.00205131  0.00627096  0.00114598]\n",
      " [ 0.00302843  0.00522125  0.01292441  0.00159136 -0.00119387]\n",
      " [ 0.00957268  0.00802879 -0.01205141 -0.02213052  0.00172143]\n",
      " [ 0.015408    0.00901573  0.01674093  0.00481649  0.01711814]\n",
      " [ 0.00365021 -0.00262143  0.01595281 -0.00309025  0.00598021]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 3\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01450055  0.00220984 -0.00938417  0.00607279  0.01156882]\n",
      " [ 0.00831623 -0.00383383  0.01091386 -0.01062986  0.00580767]\n",
      " [ 0.02344267  0.0015142  -0.00669807  0.00215481 -0.01133114]\n",
      " [-0.00104221 -0.02423056  0.00116828  0.00190574 -0.00707759]\n",
      " [-0.01281743  0.01209683 -0.00397696  0.0041227   0.01281901]\n",
      " [ 0.01780662 -0.00060419 -0.00205131  0.00627096  0.00114598]\n",
      " [ 0.00302843  0.00522125  0.01292441  0.00159136 -0.00119387]\n",
      " [ 0.00957268  0.00802879 -0.01205141 -0.02213052  0.00172143]\n",
      " [ 0.015408    0.00901573  0.01674093  0.00481649  0.01711814]\n",
      " [ 0.00365021 -0.00262143  0.01595281 -0.00309025  0.00598021]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 4\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 1.55012404e-03  1.55012404e-03  1.55012404e-03  1.55012404e-03\n",
      "   1.55012404e-03]\n",
      " [ 9.53683917e-04  9.53683917e-04  9.53683917e-04  9.53683917e-04\n",
      "   9.53683917e-04]\n",
      " [ 2.00734885e-03  2.00734885e-03  2.00734885e-03  2.00734885e-03\n",
      "   2.00734885e-03]\n",
      " [ 1.98742598e-03  1.98742598e-03  1.98742598e-03  1.98742598e-03\n",
      "   1.98742598e-03]\n",
      " [ 6.93864419e-04  6.93864419e-04  6.93864419e-04  6.93864419e-04\n",
      "   6.93864419e-04]\n",
      " [ 2.61597224e-04  2.61597224e-04  2.61597224e-04  2.61597224e-04\n",
      "   2.61597224e-04]\n",
      " [ 2.74480373e-04  2.74480373e-04  2.74480373e-04  2.74480373e-04\n",
      "   2.74480373e-04]\n",
      " [ 1.17153559e-03  1.17153559e-03  1.17153559e-03  1.17153559e-03\n",
      "   1.17153559e-03]\n",
      " [-8.98141425e-03 -8.98141425e-03 -8.98141425e-03 -8.98141425e-03\n",
      "  -8.98141425e-03]\n",
      " [ 8.14567233e-05  8.14567233e-05  8.14567233e-05  8.14567233e-05\n",
      "   8.14567233e-05]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01451605  0.00219434 -0.00939967  0.00605729  0.01155332]\n",
      " [ 0.0083067  -0.00384337  0.01090433 -0.0106394   0.00579814]\n",
      " [ 0.02342259  0.00149413 -0.00671815  0.00213473 -0.01135121]\n",
      " [-0.00106208 -0.02425044  0.0011484   0.00188587 -0.00709747]\n",
      " [-0.01282437  0.01208989 -0.00398389  0.00411576  0.01281207]\n",
      " [ 0.017804   -0.00060681 -0.00205392  0.00626835  0.00114336]\n",
      " [ 0.00302569  0.0052185   0.01292167  0.00158861 -0.00119661]\n",
      " [ 0.00956097  0.00801708 -0.01206312 -0.02214223  0.00170972]\n",
      " [ 0.01549782  0.00910555  0.01683074  0.0049063   0.01720795]\n",
      " [ 0.0036494  -0.00262225  0.015952   -0.00309107  0.0059794 ]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 5\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01451605  0.00219434 -0.00939967  0.00605729  0.01155332]\n",
      " [ 0.0083067  -0.00384337  0.01090433 -0.0106394   0.00579814]\n",
      " [ 0.02342259  0.00149413 -0.00671815  0.00213473 -0.01135121]\n",
      " [-0.00106208 -0.02425044  0.0011484   0.00188587 -0.00709747]\n",
      " [-0.01282437  0.01208989 -0.00398389  0.00411576  0.01281207]\n",
      " [ 0.017804   -0.00060681 -0.00205392  0.00626835  0.00114336]\n",
      " [ 0.00302569  0.0052185   0.01292167  0.00158861 -0.00119661]\n",
      " [ 0.00956097  0.00801708 -0.01206312 -0.02214223  0.00170972]\n",
      " [ 0.01549782  0.00910555  0.01683074  0.0049063   0.01720795]\n",
      " [ 0.0036494  -0.00262225  0.015952   -0.00309107  0.0059794 ]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 6\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 2.90729324e-03  2.90729324e-03  2.90729324e-03  2.90729324e-03\n",
      "   2.90729324e-03]\n",
      " [ 7.36176213e-04  7.36176213e-04  7.36176213e-04  7.36176213e-04\n",
      "   7.36176213e-04]\n",
      " [ 1.28321813e-03  1.28321813e-03  1.28321813e-03  1.28321813e-03\n",
      "   1.28321813e-03]\n",
      " [ 1.26659479e-03  1.26659479e-03  1.26659479e-03  1.26659479e-03\n",
      "   1.26659479e-03]\n",
      " [-9.43597634e-03 -9.43597634e-03 -9.43597634e-03 -9.43597634e-03\n",
      "  -9.43597634e-03]\n",
      " [ 2.33080777e-04  2.33080777e-04  2.33080777e-04  2.33080777e-04\n",
      "   2.33080777e-04]\n",
      " [ 2.43861829e-04  2.43861829e-04  2.43861829e-04  2.43861829e-04\n",
      "   2.43861829e-04]\n",
      " [ 8.65159334e-04  8.65159334e-04  8.65159334e-04  8.65159334e-04\n",
      "   8.65159334e-04]\n",
      " [ 1.82512350e-03  1.82512350e-03  1.82512350e-03  1.82512350e-03\n",
      "   1.82512350e-03]\n",
      " [ 7.55633873e-05  7.55633873e-05  7.55633873e-05  7.55633873e-05\n",
      "   7.55633873e-05]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01454513  0.00216526 -0.00942874  0.00602821  0.01152424]\n",
      " [ 0.00829934 -0.00385073  0.01089697 -0.01064676  0.00579078]\n",
      " [ 0.02340976  0.00148129 -0.00673098  0.0021219  -0.01136404]\n",
      " [-0.00107475 -0.0242631   0.00113574  0.0018732  -0.00711013]\n",
      " [-0.01273001  0.01218425 -0.00388954  0.00421012  0.01290643]\n",
      " [ 0.01780167 -0.00060914 -0.00205625  0.00626602  0.00114103]\n",
      " [ 0.00302325  0.00521606  0.01291923  0.00158618 -0.00119905]\n",
      " [ 0.00955232  0.00800843 -0.01207177 -0.02215088  0.00170106]\n",
      " [ 0.01547957  0.0090873   0.01681249  0.00488805  0.0171897 ]\n",
      " [ 0.00364864 -0.002623    0.01595124 -0.00309182  0.00597864]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 7\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 3.98877568e-04  3.98877568e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 9.00139902e-03  9.00139902e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 1.15622895e+00  1.15622895e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 7.71376982e-06  7.71376982e-06  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 5.35409260e-03  5.35409260e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 7.27233540e-02  7.27233540e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.19797281e-03  8.19797281e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-2.30295411e+00 -2.30295411e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 1.28403379e+00  1.28403379e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 4.15017106e-04  4.15017106e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01454911  0.00216127 -0.00942874  0.00602821  0.01152424]\n",
      " [ 0.00820932 -0.00394075  0.01089697 -0.01064676  0.00579078]\n",
      " [ 0.01184747 -0.010081   -0.00673098  0.0021219  -0.01136404]\n",
      " [-0.00107482 -0.02426318  0.00113574  0.0018732  -0.00711013]\n",
      " [-0.01278355  0.01213071 -0.00388954  0.00421012  0.01290643]\n",
      " [ 0.01707444 -0.00133637 -0.00205625  0.00626602  0.00114103]\n",
      " [ 0.00294127  0.00513408  0.01291923  0.00158618 -0.00119905]\n",
      " [ 0.03258186  0.03103797 -0.01207177 -0.02215088  0.00170106]\n",
      " [ 0.00263923 -0.00375304  0.01681249  0.00488805  0.0171897 ]\n",
      " [ 0.00364449 -0.00262715  0.01595124 -0.00309182  0.00597864]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 8\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.70220545e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.10224632e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.62498784e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.60058746e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   8.13358122e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.19749708e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.01462022e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.18192397e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.17482832e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.37834484e-02]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01454911  0.00216127 -0.00942874  0.00602821  0.0285463 ]\n",
      " [ 0.00820932 -0.00394075  0.01089697 -0.01064676  0.00468853]\n",
      " [ 0.01184747 -0.010081   -0.00673098  0.0021219  -0.01138029]\n",
      " [-0.00107482 -0.02426318  0.00113574  0.0018732  -0.00718614]\n",
      " [-0.01278355  0.01213071 -0.00388954  0.00421012  0.00477285]\n",
      " [ 0.01707444 -0.00133637 -0.00205625  0.00626602  0.00102128]\n",
      " [ 0.00294127  0.00513408  0.01291923  0.00158618 -0.0012692 ]\n",
      " [ 0.03258186  0.03103797 -0.01207177 -0.02215088  0.00051914]\n",
      " [ 0.00263923 -0.00375304  0.01681249  0.00488805  0.00544142]\n",
      " [ 0.00364449 -0.00262715  0.01595124 -0.00309182  0.00584081]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 9\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 0.00400665  0.00400665  0.00400665  0.00400665  0.00400665]\n",
      " [ 0.00058975  0.00058975  0.00058975  0.00058975  0.00058975]\n",
      " [ 0.00062792  0.00062792  0.00062792  0.00062792  0.00062792]\n",
      " [ 0.00098152  0.00098152  0.00098152  0.00098152  0.00098152]\n",
      " [ 0.00097865  0.00097865  0.00097865  0.00097865  0.00097865]\n",
      " [ 0.00019895  0.00019895  0.00019895  0.00019895  0.00019895]\n",
      " [ 0.00021103  0.00021103  0.00021103  0.00021103  0.00021103]\n",
      " [ 0.00184119  0.00184119  0.00184119  0.00184119  0.00184119]\n",
      " [ 0.00049774  0.00049774  0.00049774  0.00049774  0.00049774]\n",
      " [-0.00993331 -0.00993331 -0.00993331 -0.00993331 -0.00993331]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01458918  0.00212121 -0.00946881  0.00598815  0.02850623]\n",
      " [ 0.00820342 -0.00394664  0.01089107 -0.01065266  0.00468263]\n",
      " [ 0.01184119 -0.01008727 -0.00673726  0.00211562 -0.01138657]\n",
      " [-0.00108464 -0.02427299  0.00112592  0.00186339 -0.00719596]\n",
      " [-0.01279333  0.01212092 -0.00389932  0.00420034  0.00476306]\n",
      " [ 0.01707245 -0.00133836 -0.00205824  0.00626403  0.00101929]\n",
      " [ 0.00293916  0.00513197  0.01291712  0.00158407 -0.00127131]\n",
      " [ 0.03256344  0.03101956 -0.01209019 -0.0221693   0.00050073]\n",
      " [ 0.00263425 -0.00375802  0.01680751  0.00488307  0.00543644]\n",
      " [ 0.00374383 -0.00252782  0.01605058 -0.00299249  0.00594014]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 10\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01458918  0.00212121 -0.00946881  0.00598815  0.02850623]\n",
      " [ 0.00820342 -0.00394664  0.01089107 -0.01065266  0.00468263]\n",
      " [ 0.01184119 -0.01008727 -0.00673726  0.00211562 -0.01138657]\n",
      " [-0.00108464 -0.02427299  0.00112592  0.00186339 -0.00719596]\n",
      " [-0.01279333  0.01212092 -0.00389932  0.00420034  0.00476306]\n",
      " [ 0.01707245 -0.00133836 -0.00205824  0.00626403  0.00101929]\n",
      " [ 0.00293916  0.00513197  0.01291712  0.00158407 -0.00127131]\n",
      " [ 0.03256344  0.03101956 -0.01209019 -0.0221693   0.00050073]\n",
      " [ 0.00263425 -0.00375802  0.01680751  0.00488307  0.00543644]\n",
      " [ 0.00374383 -0.00252782  0.01605058 -0.00299249  0.00594014]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 11\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01458918  0.00212121 -0.00946881  0.00598815  0.02850623]\n",
      " [ 0.00820342 -0.00394664  0.01089107 -0.01065266  0.00468263]\n",
      " [ 0.01184119 -0.01008727 -0.00673726  0.00211562 -0.01138657]\n",
      " [-0.00108464 -0.02427299  0.00112592  0.00186339 -0.00719596]\n",
      " [-0.01279333  0.01212092 -0.00389932  0.00420034  0.00476306]\n",
      " [ 0.01707245 -0.00133836 -0.00205824  0.00626403  0.00101929]\n",
      " [ 0.00293916  0.00513197  0.01291712  0.00158407 -0.00127131]\n",
      " [ 0.03256344  0.03101956 -0.01209019 -0.0221693   0.00050073]\n",
      " [ 0.00263425 -0.00375802  0.01680751  0.00488307  0.00543644]\n",
      " [ 0.00374383 -0.00252782  0.01605058 -0.00299249  0.00594014]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 12\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01458918  0.00212121 -0.00946881  0.00598815  0.02850623]\n",
      " [ 0.00820342 -0.00394664  0.01089107 -0.01065266  0.00468263]\n",
      " [ 0.01184119 -0.01008727 -0.00673726  0.00211562 -0.01138657]\n",
      " [-0.00108464 -0.02427299  0.00112592  0.00186339 -0.00719596]\n",
      " [-0.01279333  0.01212092 -0.00389932  0.00420034  0.00476306]\n",
      " [ 0.01707245 -0.00133836 -0.00205824  0.00626403  0.00101929]\n",
      " [ 0.00293916  0.00513197  0.01291712  0.00158407 -0.00127131]\n",
      " [ 0.03256344  0.03101956 -0.01209019 -0.0221693   0.00050073]\n",
      " [ 0.00263425 -0.00375802  0.01680751  0.00488307  0.00543644]\n",
      " [ 0.00374383 -0.00252782  0.01605058 -0.00299249  0.00594014]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 13\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 0.00261253  0.00261253  0.00261253  0.00261253  0.00261253]\n",
      " [ 0.00054902  0.00054902  0.00054902  0.00054902  0.00054902]\n",
      " [ 0.00057324  0.00057324  0.00057324  0.00057324  0.00057324]\n",
      " [ 0.00212618  0.00212618  0.00212618  0.00212618  0.00212618]\n",
      " [-0.00814708 -0.00814708 -0.00814708 -0.00814708 -0.00814708]\n",
      " [ 0.00021931  0.00021931  0.00021931  0.00021931  0.00021931]\n",
      " [ 0.00023134  0.00023134  0.00023134  0.00023134  0.00023134]\n",
      " [ 0.00114926  0.00114926  0.00114926  0.00114926  0.00114926]\n",
      " [ 0.0004822   0.0004822   0.0004822   0.0004822   0.0004822 ]\n",
      " [ 0.00020409  0.00020409  0.00020409  0.00020409  0.00020409]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01461531  0.00209508 -0.00949494  0.00596202  0.02848011]\n",
      " [ 0.00819793 -0.00395213  0.01088558 -0.01065815  0.00467714]\n",
      " [ 0.01183546 -0.01009301 -0.00674299  0.00210989 -0.01139231]\n",
      " [-0.0011059  -0.02429426  0.00110466  0.00184212 -0.00721722]\n",
      " [-0.01271186  0.01220239 -0.00381785  0.00428181  0.00484453]\n",
      " [ 0.01707026 -0.00134056 -0.00206044  0.00626184  0.0010171 ]\n",
      " [ 0.00293685  0.00512966  0.01291481  0.00158175 -0.00127362]\n",
      " [ 0.03255195  0.03100806 -0.01210168 -0.02218079  0.00048924]\n",
      " [ 0.00262943 -0.00376284  0.01680269  0.00487825  0.00543162]\n",
      " [ 0.00374178 -0.00252986  0.01604854 -0.00299453  0.0059381 ]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 14\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 1.09205411e-01  1.09205411e-01  1.09205411e-01  1.09205411e-01\n",
      "   1.09205411e-01]\n",
      " [ 1.34131002e-02  1.34131002e-02  1.34131002e-02  1.34131002e-02\n",
      "   1.34131002e-02]\n",
      " [ 3.67392987e-05  3.67392987e-05  3.67392987e-05  3.67392987e-05\n",
      "   3.67392987e-05]\n",
      " [ 2.32492174e-06  2.32492174e-06  2.32492174e-06  2.32492174e-06\n",
      "   2.32492174e-06]\n",
      " [ 3.48718686e-02  3.48718686e-02  3.48718686e-02  3.48718686e-02\n",
      "   3.48718686e-02]\n",
      " [ 1.03089086e-01  1.03089086e-01  1.03089086e-01  1.03089086e-01\n",
      "   1.03089086e-01]\n",
      " [ 1.17013993e-01  1.17013993e-01  1.17013993e-01  1.17013993e-01\n",
      "   1.17013993e-01]\n",
      " [-7.39682637e-01 -7.39682637e-01 -7.39682637e-01 -7.39682637e-01\n",
      "  -7.39682637e-01]\n",
      " [ 5.44525605e-01  5.44525605e-01  5.44525605e-01  5.44525605e-01\n",
      "   5.44525605e-01]\n",
      " [ 8.10702723e-02  8.10702723e-02  8.10702723e-02  8.10702723e-02\n",
      "   8.10702723e-02]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57073602e-02  1.00302898e-03 -1.05869896e-02  4.86996698e-03\n",
      "   2.73880514e-02]\n",
      " [ 8.06380263e-03 -4.08626453e-03  1.07514471e-02 -1.07922769e-02\n",
      "   4.54301118e-03]\n",
      " [ 1.18350917e-02 -1.00933741e-02 -6.74335841e-03  2.10952295e-03\n",
      "  -1.13926737e-02]\n",
      " [-1.10592287e-03 -2.42942798e-02  1.10463646e-03  1.84210117e-03\n",
      "  -7.21724106e-03]\n",
      " [-1.30605810e-02  1.18536756e-02 -4.16656952e-03  3.93308832e-03\n",
      "   4.49581356e-03]\n",
      " [ 1.60393651e-02 -2.37144743e-03 -3.09132620e-03  5.23094468e-03\n",
      "  -1.37926534e-05]\n",
      " [ 1.76670771e-03  3.95951839e-03  1.17446657e-02  4.11612044e-04\n",
      "  -2.44376088e-03]\n",
      " [ 3.99487787e-02  3.84048910e-02 -4.70485251e-03 -1.47839617e-02\n",
      "   7.88606208e-03]\n",
      " [-2.81582564e-03 -9.20809745e-03  1.13574346e-02 -5.67006093e-04\n",
      "  -1.36367572e-05]\n",
      " [ 2.93108194e-03 -3.34056515e-03  1.52378341e-02 -3.80523356e-03\n",
      "   5.12739450e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 15\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 2.36531949e-06  2.36531949e-06  2.36531949e-06  2.36531949e-06\n",
      "   2.36531949e-06]\n",
      " [ 9.25424534e-07  9.25424534e-07  9.25424534e-07  9.25424534e-07\n",
      "   9.25424534e-07]\n",
      " [ 2.97937508e-09  2.97937508e-09  2.97937508e-09  2.97937508e-09\n",
      "   2.97937508e-09]\n",
      " [ 1.88618565e-10  1.88618565e-10  1.88618565e-10  1.88618565e-10\n",
      "   1.88618565e-10]\n",
      " [ 1.85635513e-06  1.85635513e-06  1.85635513e-06  1.85635513e-06\n",
      "   1.85635513e-06]\n",
      " [ 2.40446560e-06  2.40446560e-06  2.40446560e-06  2.40446560e-06\n",
      "   2.40446560e-06]\n",
      " [-2.54999769e+00 -2.54999769e+00 -2.54999769e+00 -2.54999769e+00\n",
      "  -2.54999769e+00]\n",
      " [ 2.54998761e+00  2.54998761e+00  2.54998761e+00  2.54998761e+00\n",
      "   2.54998761e+00]\n",
      " [ 5.81961077e-08  5.81961077e-08  5.81961077e-08  5.81961077e-08\n",
      "   5.81961077e-08]\n",
      " [ 2.46833818e-06  2.46833818e-06  2.46833818e-06  2.46833818e-06\n",
      "   2.46833818e-06]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57073838e-02  1.00300532e-03 -1.05870132e-02  4.86994333e-03\n",
      "   2.73880278e-02]\n",
      " [ 8.06379338e-03 -4.08627379e-03  1.07514378e-02 -1.07922861e-02\n",
      "   4.54300192e-03]\n",
      " [ 1.18350916e-02 -1.00933741e-02 -6.74335844e-03  2.10952292e-03\n",
      "  -1.13926738e-02]\n",
      " [-1.10592288e-03 -2.42942798e-02  1.10463646e-03  1.84210117e-03\n",
      "  -7.21724106e-03]\n",
      " [-1.30605995e-02  1.18536570e-02 -4.16658808e-03  3.93306975e-03\n",
      "   4.49579500e-03]\n",
      " [ 1.60393411e-02 -2.37147148e-03 -3.09135025e-03  5.23092064e-03\n",
      "  -1.38166981e-05]\n",
      " [ 2.72666847e-02  2.94594953e-02  3.72446426e-02  2.59115890e-02\n",
      "   2.30562161e-02]\n",
      " [ 1.44489026e-02  1.29050149e-02 -3.02047286e-02 -4.02838378e-02\n",
      "  -1.76138141e-02]\n",
      " [-2.81582622e-03 -9.20809803e-03  1.13574340e-02 -5.67006675e-04\n",
      "  -1.36373391e-05]\n",
      " [ 2.93105726e-03 -3.34058983e-03  1.52378094e-02 -3.80525824e-03\n",
      "   5.12736982e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 16\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57073838e-02  1.00300532e-03 -1.05870132e-02  4.86994333e-03\n",
      "   2.73880278e-02]\n",
      " [ 8.06379338e-03 -4.08627379e-03  1.07514378e-02 -1.07922861e-02\n",
      "   4.54300192e-03]\n",
      " [ 1.18350916e-02 -1.00933741e-02 -6.74335844e-03  2.10952292e-03\n",
      "  -1.13926738e-02]\n",
      " [-1.10592288e-03 -2.42942798e-02  1.10463646e-03  1.84210117e-03\n",
      "  -7.21724106e-03]\n",
      " [-1.30605995e-02  1.18536570e-02 -4.16658808e-03  3.93306975e-03\n",
      "   4.49579500e-03]\n",
      " [ 1.60393411e-02 -2.37147148e-03 -3.09135025e-03  5.23092064e-03\n",
      "  -1.38166981e-05]\n",
      " [ 2.72666847e-02  2.94594953e-02  3.72446426e-02  2.59115890e-02\n",
      "   2.30562161e-02]\n",
      " [ 1.44489026e-02  1.29050149e-02 -3.02047286e-02 -4.02838378e-02\n",
      "  -1.76138141e-02]\n",
      " [-2.81582622e-03 -9.20809803e-03  1.13574340e-02 -5.67006675e-04\n",
      "  -1.36373391e-05]\n",
      " [ 2.93105726e-03 -3.34058983e-03  1.52378094e-02 -3.80525824e-03\n",
      "   5.12736982e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 17\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57073838e-02  1.00300532e-03 -1.05870132e-02  4.86994333e-03\n",
      "   2.73880278e-02]\n",
      " [ 8.06379338e-03 -4.08627379e-03  1.07514378e-02 -1.07922861e-02\n",
      "   4.54300192e-03]\n",
      " [ 1.18350916e-02 -1.00933741e-02 -6.74335844e-03  2.10952292e-03\n",
      "  -1.13926738e-02]\n",
      " [-1.10592288e-03 -2.42942798e-02  1.10463646e-03  1.84210117e-03\n",
      "  -7.21724106e-03]\n",
      " [-1.30605995e-02  1.18536570e-02 -4.16658808e-03  3.93306975e-03\n",
      "   4.49579500e-03]\n",
      " [ 1.60393411e-02 -2.37147148e-03 -3.09135025e-03  5.23092064e-03\n",
      "  -1.38166981e-05]\n",
      " [ 2.72666847e-02  2.94594953e-02  3.72446426e-02  2.59115890e-02\n",
      "   2.30562161e-02]\n",
      " [ 1.44489026e-02  1.29050149e-02 -3.02047286e-02 -4.02838378e-02\n",
      "  -1.76138141e-02]\n",
      " [-2.81582622e-03 -9.20809803e-03  1.13574340e-02 -5.67006675e-04\n",
      "  -1.36373391e-05]\n",
      " [ 2.93105726e-03 -3.34058983e-03  1.52378094e-02 -3.80525824e-03\n",
      "   5.12736982e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 18\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57073838e-02  1.00300532e-03 -1.05870132e-02  4.86994333e-03\n",
      "   2.73880278e-02]\n",
      " [ 8.06379338e-03 -4.08627379e-03  1.07514378e-02 -1.07922861e-02\n",
      "   4.54300192e-03]\n",
      " [ 1.18350916e-02 -1.00933741e-02 -6.74335844e-03  2.10952292e-03\n",
      "  -1.13926738e-02]\n",
      " [-1.10592288e-03 -2.42942798e-02  1.10463646e-03  1.84210117e-03\n",
      "  -7.21724106e-03]\n",
      " [-1.30605995e-02  1.18536570e-02 -4.16658808e-03  3.93306975e-03\n",
      "   4.49579500e-03]\n",
      " [ 1.60393411e-02 -2.37147148e-03 -3.09135025e-03  5.23092064e-03\n",
      "  -1.38166981e-05]\n",
      " [ 2.72666847e-02  2.94594953e-02  3.72446426e-02  2.59115890e-02\n",
      "   2.30562161e-02]\n",
      " [ 1.44489026e-02  1.29050149e-02 -3.02047286e-02 -4.02838378e-02\n",
      "  -1.76138141e-02]\n",
      " [-2.81582622e-03 -9.20809803e-03  1.13574340e-02 -5.67006675e-04\n",
      "  -1.36373391e-05]\n",
      " [ 2.93105726e-03 -3.34058983e-03  1.52378094e-02 -3.80525824e-03\n",
      "   5.12736982e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 19\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57073838e-02  1.00300532e-03 -1.05870132e-02  4.86994333e-03\n",
      "   2.73880278e-02]\n",
      " [ 8.06379338e-03 -4.08627379e-03  1.07514378e-02 -1.07922861e-02\n",
      "   4.54300192e-03]\n",
      " [ 1.18350916e-02 -1.00933741e-02 -6.74335844e-03  2.10952292e-03\n",
      "  -1.13926738e-02]\n",
      " [-1.10592288e-03 -2.42942798e-02  1.10463646e-03  1.84210117e-03\n",
      "  -7.21724106e-03]\n",
      " [-1.30605995e-02  1.18536570e-02 -4.16658808e-03  3.93306975e-03\n",
      "   4.49579500e-03]\n",
      " [ 1.60393411e-02 -2.37147148e-03 -3.09135025e-03  5.23092064e-03\n",
      "  -1.38166981e-05]\n",
      " [ 2.72666847e-02  2.94594953e-02  3.72446426e-02  2.59115890e-02\n",
      "   2.30562161e-02]\n",
      " [ 1.44489026e-02  1.29050149e-02 -3.02047286e-02 -4.02838378e-02\n",
      "  -1.76138141e-02]\n",
      " [-2.81582622e-03 -9.20809803e-03  1.13574340e-02 -5.67006675e-04\n",
      "  -1.36373391e-05]\n",
      " [ 2.93105726e-03 -3.34058983e-03  1.52378094e-02 -3.80525824e-03\n",
      "   5.12736982e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 20\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 0.00117755  0.00117755  0.00117755  0.00117755  0.00117755]\n",
      " [ 0.00048453  0.00048453  0.00048453  0.00048453  0.00048453]\n",
      " [ 0.00207673  0.00207673  0.00207673  0.00207673  0.00207673]\n",
      " [ 0.00243992  0.00243992  0.00243992  0.00243992  0.00243992]\n",
      " [-0.00840139 -0.00840139 -0.00840139 -0.00840139 -0.00840139]\n",
      " [ 0.00060418  0.00060418  0.00060418  0.00060418  0.00060418]\n",
      " [ 0.0006186   0.0006186   0.0006186   0.0006186   0.0006186 ]\n",
      " [ 0.00041159  0.00041159  0.00041159  0.00041159  0.00041159]\n",
      " [ 0.00037882  0.00037882  0.00037882  0.00037882  0.00037882]\n",
      " [ 0.00020957  0.00020957  0.00020957  0.00020957  0.00020957]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57191594e-02  9.91229806e-04 -1.05987887e-02  4.85816781e-03\n",
      "   2.73762522e-02]\n",
      " [ 8.05894809e-03 -4.09111908e-03  1.07465926e-02 -1.07971314e-02\n",
      "   4.53815663e-03]\n",
      " [ 1.18143243e-02 -1.01141414e-02 -6.76412575e-03  2.08875561e-03\n",
      "  -1.14134411e-02]\n",
      " [-1.13032207e-03 -2.43186790e-02  1.08023727e-03  1.81770197e-03\n",
      "  -7.24164026e-03]\n",
      " [-1.29765856e-02  1.19376709e-02 -4.08257419e-03  4.01708364e-03\n",
      "   4.57980889e-03]\n",
      " [ 1.60332992e-02 -2.37751331e-03 -3.09739207e-03  5.22487881e-03\n",
      "  -1.98585255e-05]\n",
      " [ 2.72604986e-02  2.94533093e-02  3.72384566e-02  2.59054030e-02\n",
      "   2.30500300e-02]\n",
      " [ 1.44447867e-02  1.29008990e-02 -3.02088445e-02 -4.02879537e-02\n",
      "  -1.76179299e-02]\n",
      " [-2.81961440e-03 -9.21188620e-03  1.13536458e-02 -5.70794852e-04\n",
      "  -1.74255165e-05]\n",
      " [ 2.92896160e-03 -3.34268549e-03  1.52357138e-02 -3.80735390e-03\n",
      "   5.12527416e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 21\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57191594e-02  9.91229806e-04 -1.05987887e-02  4.85816781e-03\n",
      "   2.73762522e-02]\n",
      " [ 8.05894809e-03 -4.09111908e-03  1.07465926e-02 -1.07971314e-02\n",
      "   4.53815663e-03]\n",
      " [ 1.18143243e-02 -1.01141414e-02 -6.76412575e-03  2.08875561e-03\n",
      "  -1.14134411e-02]\n",
      " [-1.13032207e-03 -2.43186790e-02  1.08023727e-03  1.81770197e-03\n",
      "  -7.24164026e-03]\n",
      " [-1.29765856e-02  1.19376709e-02 -4.08257419e-03  4.01708364e-03\n",
      "   4.57980889e-03]\n",
      " [ 1.60332992e-02 -2.37751331e-03 -3.09739207e-03  5.22487881e-03\n",
      "  -1.98585255e-05]\n",
      " [ 2.72604986e-02  2.94533093e-02  3.72384566e-02  2.59054030e-02\n",
      "   2.30500300e-02]\n",
      " [ 1.44447867e-02  1.29008990e-02 -3.02088445e-02 -4.02879537e-02\n",
      "  -1.76179299e-02]\n",
      " [-2.81961440e-03 -9.21188620e-03  1.13536458e-02 -5.70794852e-04\n",
      "  -1.74255165e-05]\n",
      " [ 2.92896160e-03 -3.34268549e-03  1.52357138e-02 -3.80735390e-03\n",
      "   5.12527416e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 22\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 0.00082169  0.00082169  0.00082169  0.00082169  0.00082169]\n",
      " [ 0.00038642  0.00038642  0.00038642  0.00038642  0.00038642]\n",
      " [ 0.00336865  0.00336865  0.00336865  0.00336865  0.00336865]\n",
      " [ 0.00137122  0.00137122  0.00137122  0.00137122  0.00137122]\n",
      " [ 0.00227981  0.00227981  0.00227981  0.00227981  0.00227981]\n",
      " [ 0.00047052  0.00047052  0.00047052  0.00047052  0.00047052]\n",
      " [ 0.00048375  0.00048375  0.00048375  0.00048375  0.00048375]\n",
      " [ 0.00033224  0.00033224  0.00033224  0.00033224  0.00033224]\n",
      " [ 0.00030867  0.00030867  0.00030867  0.00030867  0.00030867]\n",
      " [-0.0098229  -0.0098229  -0.0098229  -0.0098229  -0.0098229 ]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57273762e-02  9.83012924e-04 -1.06070056e-02  4.84995093e-03\n",
      "   2.73680354e-02]\n",
      " [ 8.05508388e-03 -4.09498329e-03  1.07427283e-02 -1.08009956e-02\n",
      "   4.53429242e-03]\n",
      " [ 1.17806378e-02 -1.01478280e-02 -6.79781228e-03  2.05506907e-03\n",
      "  -1.14471276e-02]\n",
      " [-1.14403428e-03 -2.43323912e-02  1.06652506e-03  1.80398977e-03\n",
      "  -7.25535246e-03]\n",
      " [-1.29993837e-02  1.19148728e-02 -4.10537226e-03  3.99428557e-03\n",
      "   4.55701082e-03]\n",
      " [ 1.60285940e-02 -2.38221850e-03 -3.10209727e-03  5.22017361e-03\n",
      "  -2.45637189e-05]\n",
      " [ 2.72556611e-02  2.94484718e-02  3.72336191e-02  2.59005654e-02\n",
      "   2.30451925e-02]\n",
      " [ 1.44414643e-02  1.28975766e-02 -3.02121670e-02 -4.02912761e-02\n",
      "  -1.76212524e-02]\n",
      " [-2.82270113e-03 -9.21497293e-03  1.13505591e-02 -5.73881582e-04\n",
      "  -2.05122459e-05]\n",
      " [ 3.02719057e-03 -3.24445653e-03  1.53339428e-02 -3.70912494e-03\n",
      "   5.22350313e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 23\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57273762e-02  9.83012924e-04 -1.06070056e-02  4.84995093e-03\n",
      "   2.73680354e-02]\n",
      " [ 8.05508388e-03 -4.09498329e-03  1.07427283e-02 -1.08009956e-02\n",
      "   4.53429242e-03]\n",
      " [ 1.17806378e-02 -1.01478280e-02 -6.79781228e-03  2.05506907e-03\n",
      "  -1.14471276e-02]\n",
      " [-1.14403428e-03 -2.43323912e-02  1.06652506e-03  1.80398977e-03\n",
      "  -7.25535246e-03]\n",
      " [-1.29993837e-02  1.19148728e-02 -4.10537226e-03  3.99428557e-03\n",
      "   4.55701082e-03]\n",
      " [ 1.60285940e-02 -2.38221850e-03 -3.10209727e-03  5.22017361e-03\n",
      "  -2.45637189e-05]\n",
      " [ 2.72556611e-02  2.94484718e-02  3.72336191e-02  2.59005654e-02\n",
      "   2.30451925e-02]\n",
      " [ 1.44414643e-02  1.28975766e-02 -3.02121670e-02 -4.02912761e-02\n",
      "  -1.76212524e-02]\n",
      " [-2.82270113e-03 -9.21497293e-03  1.13505591e-02 -5.73881582e-04\n",
      "  -2.05122459e-05]\n",
      " [ 3.02719057e-03 -3.24445653e-03  1.53339428e-02 -3.70912494e-03\n",
      "   5.22350313e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 24\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57273762e-02  9.83012924e-04 -1.06070056e-02  4.84995093e-03\n",
      "   2.73680354e-02]\n",
      " [ 8.05508388e-03 -4.09498329e-03  1.07427283e-02 -1.08009956e-02\n",
      "   4.53429242e-03]\n",
      " [ 1.17806378e-02 -1.01478280e-02 -6.79781228e-03  2.05506907e-03\n",
      "  -1.14471276e-02]\n",
      " [-1.14403428e-03 -2.43323912e-02  1.06652506e-03  1.80398977e-03\n",
      "  -7.25535246e-03]\n",
      " [-1.29993837e-02  1.19148728e-02 -4.10537226e-03  3.99428557e-03\n",
      "   4.55701082e-03]\n",
      " [ 1.60285940e-02 -2.38221850e-03 -3.10209727e-03  5.22017361e-03\n",
      "  -2.45637189e-05]\n",
      " [ 2.72556611e-02  2.94484718e-02  3.72336191e-02  2.59005654e-02\n",
      "   2.30451925e-02]\n",
      " [ 1.44414643e-02  1.28975766e-02 -3.02121670e-02 -4.02912761e-02\n",
      "  -1.76212524e-02]\n",
      " [-2.82270113e-03 -9.21497293e-03  1.13505591e-02 -5.73881582e-04\n",
      "  -2.05122459e-05]\n",
      " [ 3.02719057e-03 -3.24445653e-03  1.53339428e-02 -3.70912494e-03\n",
      "   5.22350313e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 25\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 0.00084473  0.00084473  0.00084473  0.00084473  0.00084473]\n",
      " [ 0.000459    0.000459    0.000459    0.000459    0.000459  ]\n",
      " [ 0.00188887  0.00188887  0.00188887  0.00188887  0.00188887]\n",
      " [ 0.00119159  0.00119159  0.00119159  0.00119159  0.00119159]\n",
      " [ 0.00160288  0.00160288  0.00160288  0.00160288  0.00160288]\n",
      " [ 0.00054314  0.00054314  0.00054314  0.00054314  0.00054314]\n",
      " [ 0.00056381  0.00056381  0.00056381  0.00056381  0.00056381]\n",
      " [-0.00960008 -0.00960008 -0.00960008 -0.00960008 -0.00960008]\n",
      " [ 0.0009538   0.0009538   0.0009538   0.0009538   0.0009538 ]\n",
      " [ 0.00155238  0.00155238  0.00155238  0.00155238  0.00155238]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57358235e-02  9.74565641e-04 -1.06154529e-02  4.84150365e-03\n",
      "   2.73595881e-02]\n",
      " [ 8.05049392e-03 -4.09957325e-03  1.07381384e-02 -1.08055856e-02\n",
      "   4.52970246e-03]\n",
      " [ 1.17617491e-02 -1.01667166e-02 -6.81670097e-03  2.03618038e-03\n",
      "  -1.14660163e-02]\n",
      " [-1.15595018e-03 -2.43443071e-02  1.05460916e-03  1.79207386e-03\n",
      "  -7.26726836e-03]\n",
      " [-1.30154125e-02  1.18988441e-02 -4.12140103e-03  3.97825680e-03\n",
      "   4.54098205e-03]\n",
      " [ 1.60231626e-02 -2.38764991e-03 -3.10752868e-03  5.21474220e-03\n",
      "  -2.99951306e-05]\n",
      " [ 2.72500230e-02  2.94428337e-02  3.72279810e-02  2.58949273e-02\n",
      "   2.30395544e-02]\n",
      " [ 1.45374651e-02  1.29935773e-02 -3.01161662e-02 -4.01952753e-02\n",
      "  -1.75252516e-02]\n",
      " [-2.83223915e-03 -9.22451096e-03  1.13410210e-02 -5.83419603e-04\n",
      "  -3.00502674e-05]\n",
      " [ 3.01166681e-03 -3.25998028e-03  1.53184190e-02 -3.72464869e-03\n",
      "   5.20797937e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 26\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57358235e-02  9.74565641e-04 -1.06154529e-02  4.84150365e-03\n",
      "   2.73595881e-02]\n",
      " [ 8.05049392e-03 -4.09957325e-03  1.07381384e-02 -1.08055856e-02\n",
      "   4.52970246e-03]\n",
      " [ 1.17617491e-02 -1.01667166e-02 -6.81670097e-03  2.03618038e-03\n",
      "  -1.14660163e-02]\n",
      " [-1.15595018e-03 -2.43443071e-02  1.05460916e-03  1.79207386e-03\n",
      "  -7.26726836e-03]\n",
      " [-1.30154125e-02  1.18988441e-02 -4.12140103e-03  3.97825680e-03\n",
      "   4.54098205e-03]\n",
      " [ 1.60231626e-02 -2.38764991e-03 -3.10752868e-03  5.21474220e-03\n",
      "  -2.99951306e-05]\n",
      " [ 2.72500230e-02  2.94428337e-02  3.72279810e-02  2.58949273e-02\n",
      "   2.30395544e-02]\n",
      " [ 1.45374651e-02  1.29935773e-02 -3.01161662e-02 -4.01952753e-02\n",
      "  -1.75252516e-02]\n",
      " [-2.83223915e-03 -9.22451096e-03  1.13410210e-02 -5.83419603e-04\n",
      "  -3.00502674e-05]\n",
      " [ 3.01166681e-03 -3.25998028e-03  1.53184190e-02 -3.72464869e-03\n",
      "   5.20797937e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 27\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 1.11022302e-14  1.11022302e-14  1.11022302e-14  1.11022302e-14\n",
      "   1.11022302e-14]\n",
      " [-2.55000000e+00 -2.55000000e+00 -2.55000000e+00 -2.55000000e+00\n",
      "  -2.55000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.32667268e-15  8.32667268e-15  8.32667268e-15  8.32667268e-15\n",
      "   8.32667268e-15]\n",
      " [ 1.58206781e-13  1.58206781e-13  1.58206781e-13  1.58206781e-13\n",
      "   1.58206781e-13]\n",
      " [ 2.55000000e+00  2.55000000e+00  2.55000000e+00  2.55000000e+00\n",
      "   2.55000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 2.77555756e-15  2.77555756e-15  2.77555756e-15  2.77555756e-15\n",
      "   2.77555756e-15]\n",
      " [ 1.66533454e-13  1.66533454e-13  1.66533454e-13  1.66533454e-13\n",
      "   1.66533454e-13]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57358235e-02  9.74565641e-04 -1.06154529e-02  4.84150365e-03\n",
      "   2.73595881e-02]\n",
      " [ 3.35504939e-02  2.14004267e-02  3.62381384e-02  1.46944144e-02\n",
      "   3.00297025e-02]\n",
      " [ 1.17617491e-02 -1.01667166e-02 -6.81670097e-03  2.03618038e-03\n",
      "  -1.14660163e-02]\n",
      " [-1.15595018e-03 -2.43443071e-02  1.05460916e-03  1.79207386e-03\n",
      "  -7.26726836e-03]\n",
      " [-1.30154125e-02  1.18988441e-02 -4.12140103e-03  3.97825680e-03\n",
      "   4.54098205e-03]\n",
      " [ 1.60231626e-02 -2.38764991e-03 -3.10752868e-03  5.21474220e-03\n",
      "  -2.99951306e-05]\n",
      " [ 1.75002301e-03  3.94283368e-03  1.17279810e-02  3.94927340e-04\n",
      "  -2.46044558e-03]\n",
      " [ 1.45374651e-02  1.29935773e-02 -3.01161662e-02 -4.01952753e-02\n",
      "  -1.75252516e-02]\n",
      " [-2.83223915e-03 -9.22451096e-03  1.13410210e-02 -5.83419603e-04\n",
      "  -3.00502674e-05]\n",
      " [ 3.01166681e-03 -3.25998028e-03  1.53184190e-02 -3.72464869e-03\n",
      "   5.20797937e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 28\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57358235e-02  9.74565641e-04 -1.06154529e-02  4.84150365e-03\n",
      "   2.73595881e-02]\n",
      " [ 3.35504939e-02  2.14004267e-02  3.62381384e-02  1.46944144e-02\n",
      "   3.00297025e-02]\n",
      " [ 1.17617491e-02 -1.01667166e-02 -6.81670097e-03  2.03618038e-03\n",
      "  -1.14660163e-02]\n",
      " [-1.15595018e-03 -2.43443071e-02  1.05460916e-03  1.79207386e-03\n",
      "  -7.26726836e-03]\n",
      " [-1.30154125e-02  1.18988441e-02 -4.12140103e-03  3.97825680e-03\n",
      "   4.54098205e-03]\n",
      " [ 1.60231626e-02 -2.38764991e-03 -3.10752868e-03  5.21474220e-03\n",
      "  -2.99951306e-05]\n",
      " [ 1.75002301e-03  3.94283368e-03  1.17279810e-02  3.94927340e-04\n",
      "  -2.46044558e-03]\n",
      " [ 1.45374651e-02  1.29935773e-02 -3.01161662e-02 -4.01952753e-02\n",
      "  -1.75252516e-02]\n",
      " [-2.83223915e-03 -9.22451096e-03  1.13410210e-02 -5.83419603e-04\n",
      "  -3.00502674e-05]\n",
      " [ 3.01166681e-03 -3.25998028e-03  1.53184190e-02 -3.72464869e-03\n",
      "   5.20797937e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 29\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57358235e-02  9.74565641e-04 -1.06154529e-02  4.84150365e-03\n",
      "   2.73595881e-02]\n",
      " [ 3.35504939e-02  2.14004267e-02  3.62381384e-02  1.46944144e-02\n",
      "   3.00297025e-02]\n",
      " [ 1.17617491e-02 -1.01667166e-02 -6.81670097e-03  2.03618038e-03\n",
      "  -1.14660163e-02]\n",
      " [-1.15595018e-03 -2.43443071e-02  1.05460916e-03  1.79207386e-03\n",
      "  -7.26726836e-03]\n",
      " [-1.30154125e-02  1.18988441e-02 -4.12140103e-03  3.97825680e-03\n",
      "   4.54098205e-03]\n",
      " [ 1.60231626e-02 -2.38764991e-03 -3.10752868e-03  5.21474220e-03\n",
      "  -2.99951306e-05]\n",
      " [ 1.75002301e-03  3.94283368e-03  1.17279810e-02  3.94927340e-04\n",
      "  -2.46044558e-03]\n",
      " [ 1.45374651e-02  1.29935773e-02 -3.01161662e-02 -4.01952753e-02\n",
      "  -1.75252516e-02]\n",
      " [-2.83223915e-03 -9.22451096e-03  1.13410210e-02 -5.83419603e-04\n",
      "  -3.00502674e-05]\n",
      " [ 3.01166681e-03 -3.25998028e-03  1.53184190e-02 -3.72464869e-03\n",
      "   5.20797937e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 30\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57358235e-02  9.74565641e-04 -1.06154529e-02  4.84150365e-03\n",
      "   2.73595881e-02]\n",
      " [ 3.35504939e-02  2.14004267e-02  3.62381384e-02  1.46944144e-02\n",
      "   3.00297025e-02]\n",
      " [ 1.17617491e-02 -1.01667166e-02 -6.81670097e-03  2.03618038e-03\n",
      "  -1.14660163e-02]\n",
      " [-1.15595018e-03 -2.43443071e-02  1.05460916e-03  1.79207386e-03\n",
      "  -7.26726836e-03]\n",
      " [-1.30154125e-02  1.18988441e-02 -4.12140103e-03  3.97825680e-03\n",
      "   4.54098205e-03]\n",
      " [ 1.60231626e-02 -2.38764991e-03 -3.10752868e-03  5.21474220e-03\n",
      "  -2.99951306e-05]\n",
      " [ 1.75002301e-03  3.94283368e-03  1.17279810e-02  3.94927340e-04\n",
      "  -2.46044558e-03]\n",
      " [ 1.45374651e-02  1.29935773e-02 -3.01161662e-02 -4.01952753e-02\n",
      "  -1.75252516e-02]\n",
      " [-2.83223915e-03 -9.22451096e-03  1.13410210e-02 -5.83419603e-04\n",
      "  -3.00502674e-05]\n",
      " [ 3.01166681e-03 -3.25998028e-03  1.53184190e-02 -3.72464869e-03\n",
      "   5.20797937e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 31\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 0.00155068  0.00155068  0.00155068  0.00155068  0.00155068]\n",
      " [ 0.00092631  0.00092631  0.00092631  0.00092631  0.00092631]\n",
      " [ 0.00204297  0.00204297  0.00204297  0.00204297  0.00204297]\n",
      " [ 0.00146638  0.00146638  0.00146638  0.00146638  0.00146638]\n",
      " [ 0.00082802  0.00082802  0.00082802  0.00082802  0.00082802]\n",
      " [ 0.00090739  0.00090739  0.00090739  0.00090739  0.00090739]\n",
      " [ 0.00015583  0.00015583  0.00015583  0.00015583  0.00015583]\n",
      " [ 0.00068791  0.00068791  0.00068791  0.00068791  0.00068791]\n",
      " [ 0.00061566  0.00061566  0.00061566  0.00061566  0.00061566]\n",
      " [-0.00918104 -0.00918104 -0.00918104 -0.00918104 -0.00918104]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57513303e-02  9.59058883e-04 -1.06309597e-02  4.82599689e-03\n",
      "   2.73440813e-02]\n",
      " [ 3.35412308e-02  2.13911636e-02  3.62288753e-02  1.46851513e-02\n",
      "   3.00204394e-02]\n",
      " [ 1.17413194e-02 -1.01871464e-02 -6.83713070e-03  2.01575065e-03\n",
      "  -1.14864460e-02]\n",
      " [-1.17061393e-03 -2.43589709e-02  1.03994541e-03  1.77741011e-03\n",
      "  -7.28193211e-03]\n",
      " [-1.30236927e-02  1.18905639e-02 -4.12968121e-03  3.96997662e-03\n",
      "   4.53270186e-03]\n",
      " [ 1.60140887e-02 -2.39672381e-03 -3.11660258e-03  5.20566831e-03\n",
      "  -3.90690285e-05]\n",
      " [ 1.74846467e-03  3.94127534e-03  1.17264226e-02  3.93368999e-04\n",
      "  -2.46200392e-03]\n",
      " [ 1.45305860e-02  1.29866983e-02 -3.01230453e-02 -4.02021544e-02\n",
      "  -1.75321307e-02]\n",
      " [-2.83839576e-03 -9.23066757e-03  1.13348644e-02 -5.89576215e-04\n",
      "  -3.62068790e-05]\n",
      " [ 3.10347717e-03 -3.16816992e-03  1.54102294e-02 -3.63283833e-03\n",
      "   5.29978973e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 32\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 7.02216063e-13  7.02216063e-13  7.02216063e-13  0.00000000e+00\n",
      "   7.02216063e-13]\n",
      " [ 2.55000000e+00  2.55000000e+00  2.55000000e+00  0.00000000e+00\n",
      "   2.55000000e+00]\n",
      " [ 5.55111512e-15  5.55111512e-15  5.55111512e-15  0.00000000e+00\n",
      "   5.55111512e-15]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 2.08166817e-13  2.08166817e-13  2.08166817e-13  0.00000000e+00\n",
      "   2.08166817e-13]\n",
      " [-2.55000000e+00 -2.55000000e+00 -2.55000000e+00  0.00000000e+00\n",
      "  -2.55000000e+00]\n",
      " [ 2.26485497e-12  2.26485497e-12  2.26485497e-12  0.00000000e+00\n",
      "   2.26485497e-12]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 1.55431223e-13  1.55431223e-13  1.55431223e-13  0.00000000e+00\n",
      "   1.55431223e-13]\n",
      " [ 1.28097533e-10  1.28097533e-10  1.28097533e-10  0.00000000e+00\n",
      "   1.28097533e-10]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57513303e-02  9.59058883e-04 -1.06309597e-02  4.82599689e-03\n",
      "   2.73440813e-02]\n",
      " [ 8.04123082e-03 -4.10883635e-03  1.07288753e-02  1.46851513e-02\n",
      "   4.52043936e-03]\n",
      " [ 1.17413194e-02 -1.01871464e-02 -6.83713070e-03  2.01575065e-03\n",
      "  -1.14864460e-02]\n",
      " [-1.17061393e-03 -2.43589709e-02  1.03994541e-03  1.77741011e-03\n",
      "  -7.28193211e-03]\n",
      " [-1.30236927e-02  1.18905639e-02 -4.12968121e-03  3.96997662e-03\n",
      "   4.53270186e-03]\n",
      " [ 4.15140887e-02  2.31032762e-02  2.23833974e-02  5.20566831e-03\n",
      "   2.54609310e-02]\n",
      " [ 1.74846467e-03  3.94127534e-03  1.17264226e-02  3.93368999e-04\n",
      "  -2.46200392e-03]\n",
      " [ 1.45305860e-02  1.29866983e-02 -3.01230453e-02 -4.02021544e-02\n",
      "  -1.75321307e-02]\n",
      " [-2.83839576e-03 -9.23066757e-03  1.13348644e-02 -5.89576215e-04\n",
      "  -3.62068790e-05]\n",
      " [ 3.10347717e-03 -3.16816992e-03  1.54102294e-02 -3.63283833e-03\n",
      "   5.29978973e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 33\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 0.00115     0.00115     0.00115     0.          0.        ]\n",
      " [ 0.00024689  0.00024689  0.00024689  0.          0.        ]\n",
      " [-0.00849738 -0.00849738 -0.00849738  0.          0.        ]\n",
      " [ 0.00113911  0.00113911  0.00113911  0.          0.        ]\n",
      " [ 0.00067865  0.00067865  0.00067865  0.          0.        ]\n",
      " [ 0.00217088  0.00217088  0.00217088  0.          0.        ]\n",
      " [ 0.00013917  0.00013917  0.00013917  0.          0.        ]\n",
      " [ 0.00061172  0.00061172  0.00061172  0.          0.        ]\n",
      " [ 0.00052122  0.00052122  0.00052122  0.          0.        ]\n",
      " [ 0.00183983  0.00183983  0.00183983  0.          0.        ]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57628303e-02  9.47558844e-04 -1.06424597e-02  4.82599689e-03\n",
      "   2.73440813e-02]\n",
      " [ 8.03876189e-03 -4.11130527e-03  1.07264064e-02  1.46851513e-02\n",
      "   4.52043936e-03]\n",
      " [ 1.18262931e-02 -1.01021726e-02 -6.75215694e-03  2.01575065e-03\n",
      "  -1.14864460e-02]\n",
      " [-1.18200499e-03 -2.43703619e-02  1.02855435e-03  1.77741011e-03\n",
      "  -7.28193211e-03]\n",
      " [-1.30304792e-02  1.18837774e-02 -4.13646775e-03  3.96997662e-03\n",
      "   4.53270186e-03]\n",
      " [ 4.14923800e-02  2.30815674e-02  2.23616887e-02  5.20566831e-03\n",
      "   2.54609310e-02]\n",
      " [ 1.74707296e-03  3.93988364e-03  1.17250309e-02  3.93368999e-04\n",
      "  -2.46200392e-03]\n",
      " [ 1.45244688e-02  1.29805810e-02 -3.01291625e-02 -4.02021544e-02\n",
      "  -1.75321307e-02]\n",
      " [-2.84360798e-03 -9.23587979e-03  1.13296522e-02 -5.89576215e-04\n",
      "  -3.62068790e-05]\n",
      " [ 3.08507883e-03 -3.18656826e-03  1.53918310e-02 -3.63283833e-03\n",
      "   5.29978973e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 34\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 0.00000000e+00  2.97583486e-06  2.97583486e-06  2.97583486e-06\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  5.35822893e-04  5.35822893e-04  5.35822893e-04\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  7.85626303e-07  7.85626303e-07  7.85626303e-07\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00 -2.54999996e+00 -2.54999996e+00 -2.54999996e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  1.24356347e-04  1.24356347e-04  1.24356347e-04\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  2.54911802e+00  2.54911802e+00  2.54911802e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  8.01491705e-05  8.01491705e-05  8.01491705e-05\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  2.52853294e-12  2.52853294e-12  2.52853294e-12\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  7.15551674e-06  7.15551674e-06  7.15551674e-06\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  1.31082448e-04  1.31082448e-04  1.31082448e-04\n",
      "   0.00000000e+00]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57628303e-02  9.47529086e-04 -1.06424894e-02  4.82596713e-03\n",
      "   2.73440813e-02]\n",
      " [ 8.03876189e-03 -4.11666350e-03  1.07210481e-02  1.46797931e-02\n",
      "   4.52043936e-03]\n",
      " [ 1.18262931e-02 -1.01021805e-02 -6.75216480e-03  2.01574280e-03\n",
      "  -1.14864460e-02]\n",
      " [-1.18200499e-03  1.12963764e-03  2.65285539e-02  2.72774097e-02\n",
      "  -7.28193211e-03]\n",
      " [-1.30304792e-02  1.18825338e-02 -4.13771132e-03  3.96873306e-03\n",
      "   4.53270186e-03]\n",
      " [ 4.14923800e-02 -2.40961273e-03 -3.12949150e-03 -2.02855119e-02\n",
      "   2.54609310e-02]\n",
      " [ 1.74707296e-03  3.93908215e-03  1.17242294e-02  3.92567507e-04\n",
      "  -2.46200392e-03]\n",
      " [ 1.45244688e-02  1.29805810e-02 -3.01291625e-02 -4.02021544e-02\n",
      "  -1.75321307e-02]\n",
      " [-2.84360798e-03 -9.23595135e-03  1.13295807e-02 -5.89647770e-04\n",
      "  -3.62068790e-05]\n",
      " [ 3.08507883e-03 -3.18787909e-03  1.53905202e-02 -3.63414916e-03\n",
      "   5.29978973e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 35\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57628303e-02  9.47529086e-04 -1.06424894e-02  4.82596713e-03\n",
      "   2.73440813e-02]\n",
      " [ 8.03876189e-03 -4.11666350e-03  1.07210481e-02  1.46797931e-02\n",
      "   4.52043936e-03]\n",
      " [ 1.18262931e-02 -1.01021805e-02 -6.75216480e-03  2.01574280e-03\n",
      "  -1.14864460e-02]\n",
      " [-1.18200499e-03  1.12963764e-03  2.65285539e-02  2.72774097e-02\n",
      "  -7.28193211e-03]\n",
      " [-1.30304792e-02  1.18825338e-02 -4.13771132e-03  3.96873306e-03\n",
      "   4.53270186e-03]\n",
      " [ 4.14923800e-02 -2.40961273e-03 -3.12949150e-03 -2.02855119e-02\n",
      "   2.54609310e-02]\n",
      " [ 1.74707296e-03  3.93908215e-03  1.17242294e-02  3.92567507e-04\n",
      "  -2.46200392e-03]\n",
      " [ 1.45244688e-02  1.29805810e-02 -3.01291625e-02 -4.02021544e-02\n",
      "  -1.75321307e-02]\n",
      " [-2.84360798e-03 -9.23595135e-03  1.13295807e-02 -5.89647770e-04\n",
      "  -3.62068790e-05]\n",
      " [ 3.08507883e-03 -3.18787909e-03  1.53905202e-02 -3.63414916e-03\n",
      "   5.29978973e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 36\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57628303e-02  9.47529086e-04 -1.06424894e-02  4.82596713e-03\n",
      "   2.73440813e-02]\n",
      " [ 8.03876189e-03 -4.11666350e-03  1.07210481e-02  1.46797931e-02\n",
      "   4.52043936e-03]\n",
      " [ 1.18262931e-02 -1.01021805e-02 -6.75216480e-03  2.01574280e-03\n",
      "  -1.14864460e-02]\n",
      " [-1.18200499e-03  1.12963764e-03  2.65285539e-02  2.72774097e-02\n",
      "  -7.28193211e-03]\n",
      " [-1.30304792e-02  1.18825338e-02 -4.13771132e-03  3.96873306e-03\n",
      "   4.53270186e-03]\n",
      " [ 4.14923800e-02 -2.40961273e-03 -3.12949150e-03 -2.02855119e-02\n",
      "   2.54609310e-02]\n",
      " [ 1.74707296e-03  3.93908215e-03  1.17242294e-02  3.92567507e-04\n",
      "  -2.46200392e-03]\n",
      " [ 1.45244688e-02  1.29805810e-02 -3.01291625e-02 -4.02021544e-02\n",
      "  -1.75321307e-02]\n",
      " [-2.84360798e-03 -9.23595135e-03  1.13295807e-02 -5.89647770e-04\n",
      "  -3.62068790e-05]\n",
      " [ 3.08507883e-03 -3.18787909e-03  1.53905202e-02 -3.63414916e-03\n",
      "   5.29978973e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 37\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57628303e-02  9.47529086e-04 -1.06424894e-02  4.82596713e-03\n",
      "   2.73440813e-02]\n",
      " [ 8.03876189e-03 -4.11666350e-03  1.07210481e-02  1.46797931e-02\n",
      "   4.52043936e-03]\n",
      " [ 1.18262931e-02 -1.01021805e-02 -6.75216480e-03  2.01574280e-03\n",
      "  -1.14864460e-02]\n",
      " [-1.18200499e-03  1.12963764e-03  2.65285539e-02  2.72774097e-02\n",
      "  -7.28193211e-03]\n",
      " [-1.30304792e-02  1.18825338e-02 -4.13771132e-03  3.96873306e-03\n",
      "   4.53270186e-03]\n",
      " [ 4.14923800e-02 -2.40961273e-03 -3.12949150e-03 -2.02855119e-02\n",
      "   2.54609310e-02]\n",
      " [ 1.74707296e-03  3.93908215e-03  1.17242294e-02  3.92567507e-04\n",
      "  -2.46200392e-03]\n",
      " [ 1.45244688e-02  1.29805810e-02 -3.01291625e-02 -4.02021544e-02\n",
      "  -1.75321307e-02]\n",
      " [-2.84360798e-03 -9.23595135e-03  1.13295807e-02 -5.89647770e-04\n",
      "  -3.62068790e-05]\n",
      " [ 3.08507883e-03 -3.18787909e-03  1.53905202e-02 -3.63414916e-03\n",
      "   5.29978973e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 38\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 1.07173103e-04  1.07173103e-04  1.07173103e-04  1.07173103e-04\n",
      "   1.07173103e-04]\n",
      " [ 7.66325126e-02  7.66325126e-02  7.66325126e-02  7.66325126e-02\n",
      "   7.66325126e-02]\n",
      " [ 1.72740414e-06  1.72740414e-06  1.72740414e-06  1.72740414e-06\n",
      "   1.72740414e-06]\n",
      " [ 1.88248566e+00  1.88248566e+00  1.88248566e+00  1.88248566e+00\n",
      "   1.88248566e+00]\n",
      " [ 2.94395796e-05  2.94395796e-05  2.94395796e-05  2.94395796e-05\n",
      "   2.94395796e-05]\n",
      " [ 6.34945540e-01  6.34945540e-01  6.34945540e-01  6.34945540e-01\n",
      "   6.34945540e-01]\n",
      " [ 1.57418294e-04  1.57418294e-04  1.57418294e-04  1.57418294e-04\n",
      "   1.57418294e-04]\n",
      " [-2.55000000e+00 -2.55000000e+00 -2.55000000e+00 -2.55000000e+00\n",
      "  -2.55000000e+00]\n",
      " [ 7.35818774e-06  7.35818774e-06  7.35818774e-06  7.35818774e-06\n",
      "   7.35818774e-06]\n",
      " [ 1.89238589e-03  1.89238589e-03  1.89238589e-03  1.89238589e-03\n",
      "   1.89238589e-03]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57639021e-02  9.46457355e-04 -1.06435612e-02  4.82489540e-03\n",
      "   2.73430096e-02]\n",
      " [ 7.27243677e-03 -4.88298863e-03  9.95472301e-03  1.39134680e-02\n",
      "   3.75411423e-03]\n",
      " [ 1.18262758e-02 -1.01021977e-02 -6.75218207e-03  2.01572552e-03\n",
      "  -1.14864633e-02]\n",
      " [-2.00068616e-02 -1.76952189e-02  7.70369735e-03  8.45255311e-03\n",
      "  -2.61067887e-02]\n",
      " [-1.30307736e-02  1.18822394e-02 -4.13800571e-03  3.96843866e-03\n",
      "   4.53240747e-03]\n",
      " [ 3.51429246e-02 -8.75906813e-03 -9.47894690e-03 -2.66349673e-02\n",
      "   1.91114756e-02]\n",
      " [ 1.74549878e-03  3.93750796e-03  1.17226553e-02  3.90993324e-04\n",
      "  -2.46357811e-03]\n",
      " [ 4.00244688e-02  3.84805810e-02 -4.62916248e-03 -1.47021544e-02\n",
      "   7.96786932e-03]\n",
      " [-2.84368156e-03 -9.23602493e-03  1.13295071e-02 -5.89721352e-04\n",
      "  -3.62804609e-05]\n",
      " [ 3.06615497e-03 -3.20680295e-03  1.53715963e-02 -3.65307302e-03\n",
      "   5.28086587e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 39\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 0.0008436   0.0008436   0.0008436   0.0008436   0.0008436 ]\n",
      " [ 0.00064258  0.00064258  0.00064258  0.00064258  0.00064258]\n",
      " [ 0.00297314  0.00297314  0.00297314  0.00297314  0.00297314]\n",
      " [ 0.0006871   0.0006871   0.0006871   0.0006871   0.0006871 ]\n",
      " [ 0.0005632   0.0005632   0.0005632   0.0005632   0.0005632 ]\n",
      " [ 0.0010938   0.0010938   0.0010938   0.0010938   0.0010938 ]\n",
      " [ 0.00013845  0.00013845  0.00013845  0.00013845  0.00013845]\n",
      " [ 0.00150018  0.00150018  0.00150018  0.00150018  0.00150018]\n",
      " [-0.00954815 -0.00954815 -0.00954815 -0.00954815 -0.00954815]\n",
      " [ 0.0011062   0.0011062   0.0011062   0.0011062   0.0011062 ]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57723380e-02  9.38021376e-04 -1.06519972e-02  4.81645942e-03\n",
      "   2.73345736e-02]\n",
      " [ 7.26601101e-03 -4.88941438e-03  9.94829725e-03  1.39070422e-02\n",
      "   3.74768848e-03]\n",
      " [ 1.17965444e-02 -1.01319292e-02 -6.78191349e-03  1.98599411e-03\n",
      "  -1.15161947e-02]\n",
      " [-2.00137326e-02 -1.77020900e-02  7.69682634e-03  8.44568210e-03\n",
      "  -2.61136597e-02]\n",
      " [-1.30364056e-02  1.18766074e-02 -4.14363768e-03  3.96280669e-03\n",
      "   4.52677550e-03]\n",
      " [ 3.51319865e-02 -8.77000616e-03 -9.48988493e-03 -2.66459053e-02\n",
      "   1.91005375e-02]\n",
      " [ 1.74411431e-03  3.93612350e-03  1.17212708e-02  3.89608859e-04\n",
      "  -2.46496257e-03]\n",
      " [ 4.00094670e-02  3.84655793e-02 -4.64416426e-03 -1.47171562e-02\n",
      "   7.95286754e-03]\n",
      " [-2.74820011e-03 -9.14054347e-03  1.14249885e-02 -4.94239893e-04\n",
      "   5.92009981e-05]\n",
      " [ 3.05509292e-03 -3.21786499e-03  1.53605343e-02 -3.66413507e-03\n",
      "   5.26980382e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 40\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 8.33519703e-07  8.33519703e-07  8.33519703e-07  8.33519703e-07\n",
      "   8.33519703e-07]\n",
      " [ 2.42131796e-04  2.42131796e-04  2.42131796e-04  2.42131796e-04\n",
      "   2.42131796e-04]\n",
      " [ 1.05550541e-08  1.05550541e-08  1.05550541e-08  1.05550541e-08\n",
      "   1.05550541e-08]\n",
      " [-2.55000000e+00 -2.55000000e+00 -2.55000000e+00 -2.55000000e+00\n",
      "  -2.55000000e+00]\n",
      " [ 2.37184281e-07  2.37184281e-07  2.37184281e-07  2.37184281e-07\n",
      "   2.37184281e-07]\n",
      " [ 2.06871010e-06  2.06871010e-06  2.06871010e-06  2.06871010e-06\n",
      "   2.06871010e-06]\n",
      " [ 1.33599679e-06  1.33599679e-06  1.33599679e-06  1.33599679e-06\n",
      "   1.33599679e-06]\n",
      " [ 2.54973925e+00  2.54973925e+00  2.54973925e+00  2.54973925e+00\n",
      "   2.54973925e+00]\n",
      " [ 1.85662760e-07  1.85662760e-07  1.85662760e-07  1.85662760e-07\n",
      "   1.85662760e-07]\n",
      " [ 1.39566225e-05  1.39566225e-05  1.39566225e-05  1.39566225e-05\n",
      "   1.39566225e-05]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57723464e-02  9.38013040e-04 -1.06520055e-02  4.81645108e-03\n",
      "   2.73345653e-02]\n",
      " [ 7.26358969e-03 -4.89183570e-03  9.94587593e-03  1.39046209e-02\n",
      "   3.74526716e-03]\n",
      " [ 1.17965443e-02 -1.01319293e-02 -6.78191360e-03  1.98599400e-03\n",
      "  -1.15161948e-02]\n",
      " [ 5.48626742e-03  7.79791004e-03  3.31968263e-02  3.39456821e-02\n",
      "  -6.13659707e-04]\n",
      " [-1.30364079e-02  1.18766050e-02 -4.14364005e-03  3.96280432e-03\n",
      "   4.52677313e-03]\n",
      " [ 3.51319659e-02 -8.77002685e-03 -9.48990562e-03 -2.66459260e-02\n",
      "   1.91005169e-02]\n",
      " [ 1.74410095e-03  3.93611014e-03  1.17212574e-02  3.89595499e-04\n",
      "  -2.46497593e-03]\n",
      " [ 1.45120745e-02  1.29681868e-02 -3.01415567e-02 -4.02145487e-02\n",
      "  -1.75445249e-02]\n",
      " [-2.74820196e-03 -9.14054532e-03  1.14249867e-02 -4.94241749e-04\n",
      "   5.91991415e-05]\n",
      " [ 3.05495336e-03 -3.21800456e-03  1.53603947e-02 -3.66427463e-03\n",
      "   5.26966426e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 41\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 3.42107776e-05  3.42107776e-05  3.42107776e-05  0.00000000e+00\n",
      "   3.42107776e-05]\n",
      " [ 9.75468475e-04  9.75468475e-04  9.75468475e-04  0.00000000e+00\n",
      "   9.75468475e-04]\n",
      " [ 8.91627482e-07  8.91627482e-07  8.91627482e-07  0.00000000e+00\n",
      "   8.91627482e-07]\n",
      " [-2.19623390e-01 -2.19623390e-01 -2.19623390e-01  0.00000000e+00\n",
      "  -2.19623390e-01]\n",
      " [ 1.21026787e-05  1.21026787e-05  1.21026787e-05  0.00000000e+00\n",
      "   1.21026787e-05]\n",
      " [ 2.15285638e-01  2.15285638e-01  2.15285638e-01  0.00000000e+00\n",
      "   2.15285638e-01]\n",
      " [ 1.69532173e-04  1.69532173e-04  1.69532173e-04  0.00000000e+00\n",
      "   1.69532173e-04]\n",
      " [ 7.09814008e-08  7.09814008e-08  7.09814008e-08  0.00000000e+00\n",
      "   7.09814008e-08]\n",
      " [ 2.95195813e-05  2.95195813e-05  2.95195813e-05  0.00000000e+00\n",
      "   2.95195813e-05]\n",
      " [ 4.95824819e-03  4.95824819e-03  4.95824819e-03  0.00000000e+00\n",
      "   4.95824819e-03]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57726885e-02  9.37670933e-04 -1.06523476e-02  4.81645108e-03\n",
      "   2.73342232e-02]\n",
      " [ 7.25383501e-03 -4.90159039e-03  9.93612125e-03  1.39046209e-02\n",
      "   3.73551248e-03]\n",
      " [ 1.17965354e-02 -1.01319382e-02 -6.78192251e-03  1.98599400e-03\n",
      "  -1.15162037e-02]\n",
      " [ 7.68250132e-03  9.99414394e-03  3.53930602e-02  3.39456821e-02\n",
      "   1.58257419e-03]\n",
      " [-1.30365290e-02  1.18764840e-02 -4.14376108e-03  3.96280432e-03\n",
      "   4.52665210e-03]\n",
      " [ 3.29791095e-02 -1.09228832e-02 -1.16427620e-02 -2.66459260e-02\n",
      "   1.69476605e-02]\n",
      " [ 1.74240563e-03  3.93441482e-03  1.17195621e-02  3.89595499e-04\n",
      "  -2.46667125e-03]\n",
      " [ 1.45120738e-02  1.29681861e-02 -3.01415574e-02 -4.02145487e-02\n",
      "  -1.75445256e-02]\n",
      " [-2.74849716e-03 -9.14084052e-03  1.14246915e-02 -4.94241749e-04\n",
      "   5.89039457e-05]\n",
      " [ 3.00537087e-03 -3.26758704e-03  1.53108122e-02 -3.66427463e-03\n",
      "   5.22008177e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 42\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-1.57726885e-02  9.37670933e-04 -1.06523476e-02  4.81645108e-03\n",
      "   2.73342232e-02]\n",
      " [ 7.25383501e-03 -4.90159039e-03  9.93612125e-03  1.39046209e-02\n",
      "   3.73551248e-03]\n",
      " [ 1.17965354e-02 -1.01319382e-02 -6.78192251e-03  1.98599400e-03\n",
      "  -1.15162037e-02]\n",
      " [ 7.68250132e-03  9.99414394e-03  3.53930602e-02  3.39456821e-02\n",
      "   1.58257419e-03]\n",
      " [-1.30365290e-02  1.18764840e-02 -4.14376108e-03  3.96280432e-03\n",
      "   4.52665210e-03]\n",
      " [ 3.29791095e-02 -1.09228832e-02 -1.16427620e-02 -2.66459260e-02\n",
      "   1.69476605e-02]\n",
      " [ 1.74240563e-03  3.93441482e-03  1.17195621e-02  3.89595499e-04\n",
      "  -2.46667125e-03]\n",
      " [ 1.45120738e-02  1.29681861e-02 -3.01415574e-02 -4.02145487e-02\n",
      "  -1.75445256e-02]\n",
      " [-2.74849716e-03 -9.14084052e-03  1.14246915e-02 -4.94241749e-04\n",
      "   5.89039457e-05]\n",
      " [ 3.00537087e-03 -3.26758704e-03  1.53108122e-02 -3.66427463e-03\n",
      "   5.22008177e-03]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 43\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 0.00075112  0.00075112  0.00075112  0.00075112  0.00075112]\n",
      " [ 0.0016229   0.0016229   0.0016229   0.0016229   0.0016229 ]\n",
      " [ 0.00182619  0.00182619  0.00182619  0.00182619  0.00182619]\n",
      " [ 0.00179723  0.00179723  0.00179723  0.00179723  0.00179723]\n",
      " [ 0.0005313   0.0005313   0.0005313   0.0005313   0.0005313 ]\n",
      " [ 0.00088159  0.00088159  0.00088159  0.00088159  0.00088159]\n",
      " [ 0.00014355  0.00014355  0.00014355  0.00014355  0.00014355]\n",
      " [ 0.00041893  0.00041893  0.00041893  0.00041893  0.00041893]\n",
      " [-0.00890806 -0.00890806 -0.00890806 -0.00890806 -0.00890806]\n",
      " [ 0.00093536  0.00093536  0.00093536  0.00093536  0.00093536]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.0157802   0.00093016 -0.01065986  0.00480894  0.02732671]\n",
      " [ 0.00723761 -0.00491782  0.00991989  0.01388839  0.00371928]\n",
      " [ 0.01177827 -0.0101502  -0.00680018  0.00196773 -0.01153447]\n",
      " [ 0.00766453  0.00997617  0.03537509  0.03392771  0.0015646 ]\n",
      " [-0.01304184  0.01187117 -0.00414907  0.00395749  0.00452134]\n",
      " [ 0.03297029 -0.0109317  -0.01165158 -0.02665474  0.01693884]\n",
      " [ 0.00174097  0.00393298  0.01171813  0.00038816 -0.00246811]\n",
      " [ 0.01450788  0.012964   -0.03014575 -0.04021874 -0.01754871]\n",
      " [-0.00265942 -0.00905176  0.01151377 -0.00040516  0.00014798]\n",
      " [ 0.00299602 -0.00327694  0.01530146 -0.00367363  0.00521073]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 44\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 0.00066743  0.00066743  0.00066743  0.00066743  0.00066743]\n",
      " [-0.00868484 -0.00868484 -0.00868484 -0.00868484 -0.00868484]\n",
      " [ 0.00144958  0.00144958  0.00144958  0.00144958  0.00144958]\n",
      " [ 0.00143079  0.00143079  0.00143079  0.00143079  0.00143079]\n",
      " [ 0.0004837   0.0004837   0.0004837   0.0004837   0.0004837 ]\n",
      " [ 0.00077234  0.00077234  0.00077234  0.00077234  0.00077234]\n",
      " [ 0.00013658  0.00013658  0.00013658  0.00013658  0.00013658]\n",
      " [ 0.00038623  0.00038623  0.00038623  0.00038623  0.00038623]\n",
      " [ 0.0025436   0.0025436   0.0025436   0.0025436   0.0025436 ]\n",
      " [ 0.0008147   0.0008147   0.0008147   0.0008147   0.0008147 ]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01578687  0.00092349 -0.01066653  0.00480227  0.02732004]\n",
      " [ 0.00732445 -0.00483097  0.01000674  0.01397524  0.00380613]\n",
      " [ 0.01176378 -0.0101647  -0.00681468  0.00195324 -0.01154896]\n",
      " [ 0.00765022  0.00996186  0.03536078  0.0339134   0.00155029]\n",
      " [-0.01304668  0.01186633 -0.00415391  0.00395265  0.0045165 ]\n",
      " [ 0.03296257 -0.01093942 -0.0116593  -0.02666247  0.01693112]\n",
      " [ 0.0017396   0.00393161  0.01171676  0.00038679 -0.00246947]\n",
      " [ 0.01450402  0.01296013 -0.03014961 -0.0402226  -0.01755258]\n",
      " [-0.00268485 -0.0090772   0.01148834 -0.0004306   0.00012255]\n",
      " [ 0.00298787 -0.00328509  0.01529331 -0.00368178  0.00520258]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 45\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01578687  0.00092349 -0.01066653  0.00480227  0.02732004]\n",
      " [ 0.00732445 -0.00483097  0.01000674  0.01397524  0.00380613]\n",
      " [ 0.01176378 -0.0101647  -0.00681468  0.00195324 -0.01154896]\n",
      " [ 0.00765022  0.00996186  0.03536078  0.0339134   0.00155029]\n",
      " [-0.01304668  0.01186633 -0.00415391  0.00395265  0.0045165 ]\n",
      " [ 0.03296257 -0.01093942 -0.0116593  -0.02666247  0.01693112]\n",
      " [ 0.0017396   0.00393161  0.01171676  0.00038679 -0.00246947]\n",
      " [ 0.01450402  0.01296013 -0.03014961 -0.0402226  -0.01755258]\n",
      " [-0.00268485 -0.0090772   0.01148834 -0.0004306   0.00012255]\n",
      " [ 0.00298787 -0.00328509  0.01529331 -0.00368178  0.00520258]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 46\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01578687  0.00092349 -0.01066653  0.00480227  0.02732004]\n",
      " [ 0.00732445 -0.00483097  0.01000674  0.01397524  0.00380613]\n",
      " [ 0.01176378 -0.0101647  -0.00681468  0.00195324 -0.01154896]\n",
      " [ 0.00765022  0.00996186  0.03536078  0.0339134   0.00155029]\n",
      " [-0.01304668  0.01186633 -0.00415391  0.00395265  0.0045165 ]\n",
      " [ 0.03296257 -0.01093942 -0.0116593  -0.02666247  0.01693112]\n",
      " [ 0.0017396   0.00393161  0.01171676  0.00038679 -0.00246947]\n",
      " [ 0.01450402  0.01296013 -0.03014961 -0.0402226  -0.01755258]\n",
      " [-0.00268485 -0.0090772   0.01148834 -0.0004306   0.00012255]\n",
      " [ 0.00298787 -0.00328509  0.01529331 -0.00368178  0.00520258]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 47\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 1.44383810e-09  1.44383810e-09  1.44383810e-09  1.44383810e-09\n",
      "   1.44383810e-09]\n",
      " [-2.54999801e+00 -2.54999801e+00 -2.54999801e+00 -2.54999801e+00\n",
      "  -2.54999801e+00]\n",
      " [ 1.11272103e-11  1.11272103e-11  1.11272103e-11  1.11272103e-11\n",
      "   1.11272103e-11]\n",
      " [ 2.54999799e+00  2.54999799e+00  2.54999799e+00  2.54999799e+00\n",
      "   2.54999799e+00]\n",
      " [ 4.58263982e-10  4.58263982e-10  4.58263982e-10  4.58263982e-10\n",
      "   4.58263982e-10]\n",
      " [ 9.70047653e-10  9.70047653e-10  9.70047653e-10  9.70047653e-10\n",
      "   9.70047653e-10]\n",
      " [ 3.17340043e-09  3.17340043e-09  3.17340043e-09  3.17340043e-09\n",
      "   3.17340043e-09]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 5.77345116e-10  5.77345116e-10  5.77345116e-10  5.77345116e-10\n",
      "   5.77345116e-10]\n",
      " [ 2.10808412e-08  2.10808412e-08  2.10808412e-08  2.10808412e-08\n",
      "   2.10808412e-08]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01578687  0.00092349 -0.01066653  0.00480227  0.02732004]\n",
      " [ 0.03282443  0.02066901  0.03550672  0.03947522  0.02930611]\n",
      " [ 0.01176378 -0.0101647  -0.00681468  0.00195324 -0.01154896]\n",
      " [-0.01784976 -0.01553812  0.0098608   0.00841342 -0.02394969]\n",
      " [-0.01304668  0.01186633 -0.00415391  0.00395265  0.0045165 ]\n",
      " [ 0.03296257 -0.01093942 -0.0116593  -0.02666247  0.01693112]\n",
      " [ 0.0017396   0.00393161  0.01171676  0.00038679 -0.00246947]\n",
      " [ 0.01450402  0.01296013 -0.03014961 -0.0402226  -0.01755258]\n",
      " [-0.00268485 -0.0090772   0.01148834 -0.0004306   0.00012255]\n",
      " [ 0.00298787 -0.00328509  0.01529331 -0.00368178  0.00520258]]\n",
      "------------------------\n",
      ">> inside grad computation main loop, i: 0\n",
      ">> inside grad computation main loop, i: 1\n",
      ">> inside grad computation main loop, i: 2\n",
      ">> inside grad computation main loop, i: 3\n",
      ">> inside grad computation main loop, i: 4\n",
      ">> inside grad computation main loop, i: 5\n",
      ">> inside grad computation main loop, i: 6\n",
      ">> inside grad computation main loop, i: 7\n",
      ">> inside grad computation main loop, i: 8\n",
      ">> inside grad computation main loop, i: 9\n",
      "******** grads computed, batch number: 48\n",
      "shape of W: (10, 5)\n",
      "shape of grad_W: (10, 5)\n",
      "shape of b: (10, 1)\n",
      "shape of grad_b: (10, 1)\n",
      "this is grad_W:\n",
      "[[ 0.00043894  0.00043894  0.00043894  0.00043894  0.00043894]\n",
      " [ 0.0045412   0.0045412   0.0045412   0.0045412   0.0045412 ]\n",
      " [-0.00922311 -0.00922311 -0.00922311 -0.00922311 -0.00922311]\n",
      " [ 0.00058706  0.00058706  0.00058706  0.00058706  0.00058706]\n",
      " [ 0.00033527  0.00033527  0.00033527  0.00033527  0.00033527]\n",
      " [ 0.00134003  0.00134003  0.00134003  0.00134003  0.00134003]\n",
      " [ 0.00010551  0.00010551  0.00010551  0.00010551  0.00010551]\n",
      " [ 0.00027426  0.00027426  0.00027426  0.00027426  0.00027426]\n",
      " [ 0.00108569  0.00108569  0.00108569  0.00108569  0.00108569]\n",
      " [ 0.00051522  0.00051522  0.00051522  0.00051522  0.00051522]]\n",
      "dtype of grad_W: float64, dtype of W: float64\n",
      "eta is: 0.01\n",
      "result of operation (temp): \n",
      "[[-0.01579126  0.0009191  -0.01067092  0.00479788  0.02731565]\n",
      " [ 0.03277902  0.0206236   0.03546131  0.03942981  0.0292607 ]\n",
      " [ 0.01185601 -0.01007246 -0.00672245  0.00204547 -0.01145673]\n",
      " [-0.01785563 -0.01554399  0.00985493  0.00840755 -0.02395556]\n",
      " [-0.01305003  0.01186298 -0.00415726  0.0039493   0.00451315]\n",
      " [ 0.03294917 -0.01095282 -0.0116727  -0.02667587  0.01691772]\n",
      " [ 0.00173855  0.00393056  0.01171571  0.00038574 -0.00247053]\n",
      " [ 0.01450128  0.01295739 -0.03015235 -0.04022534 -0.01755532]\n",
      " [-0.00269571 -0.00908805  0.01147748 -0.00044145  0.00011169]\n",
      " [ 0.00298272 -0.00329024  0.01528816 -0.00368693  0.00519743]]\n",
      "------------------------\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "probablity: \n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-845-b0f53da71063>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lprun'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-f nn.train nn.train(n_train_X[0:5, :], train_Y)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2324\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2327\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-126>\u001b[0m in \u001b[0;36mlprun\u001b[0;34m(self, parameter_s)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/line_profiler.py\u001b[0m in \u001b[0;36mlprun\u001b[0;34m(self, parameter_s)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0mprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m                 \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/line_profiler.py\u001b[0m in \u001b[0;36mrunctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_by_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mexec_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_by_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-843-798969f29834>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, Y, eta, lambda_, epochs, mini_batch_size)\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                 \u001b[0mgrad_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_grads_num_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'******** grads computed, batch number: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-843-798969f29834>\u001b[0m in \u001b[0;36mcompute_grads_num_slow\u001b[0;34m(self, X, Y, P, W, b, lamda_, h)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mb_try\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mb_try\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_try\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mb_try\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-843-798969f29834>\u001b[0m in \u001b[0;36mcompute_cost\u001b[0;34m(self, X, Y, W, b, lambda_)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%lprun -f nn.train nn.train(n_train_X[0:5, :], train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = nn.compute_cost(n_train_X, train_Y, nn.W, nn.b, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "242.4582915979156"
      ]
     },
     "metadata": {},
     "execution_count": 353
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array([1, 2, 4, 7, 11, 16], dtype=float)\n",
    "x = np.arange(f.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  4.,  7., 11., 16.])"
      ]
     },
     "metadata": {},
     "execution_count": 445
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 446
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1. , 1.5, 2.5, 3.5, 4.5, 5. ])"
      ]
     },
     "metadata": {},
     "execution_count": 449
    }
   ],
   "source": [
    "np.gradient(f, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}